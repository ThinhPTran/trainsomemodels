{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "247b72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccb6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = './Data/yolo_train_val.prototxt'\n",
    "yoloweight_filename = './Data/yolov3.weights'\n",
    "caffemodel_filename = './Data/yolo_train_val.caffemodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d425427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gencaffemodel(model_filename, yoloweight_filename, caffemodel_filename):\n",
    "    print('model file is ' + model_filename)\n",
    "    print('weight file is ' + yoloweight_filename)\n",
    "    print('caffemodel file is ' + caffemodel_filename)\n",
    "    \n",
    "    net = caffe.Net(model_filename, caffe.TEST)\n",
    "    params = net.params.keys()\n",
    "    \n",
    "    # read weights from file and assign to the network\n",
    "    netWeightsInt = np.fromfile(yoloweight_filename, dtype=np.int32)\n",
    "    transFlag = (netWeightsInt[0]>1000 or netWeightsInt[1]>1000) # transpose flag, the first 4 entries are major, minor, revision and net.seen\n",
    "    print(transFlag) \n",
    "    \n",
    "    netWeightsFloat = np.fromfile(yoloweight_filename, dtype=np.float32)\n",
    "    netWeights = netWeightsFloat[4:] # start from the 5th entry, the first 4 entries are major, minor, revision and net.seen\n",
    "    print(netWeights.shape)\n",
    "    count = 0\n",
    "    for pr in params:\n",
    "        lidx = list(net._layer_names).index(pr)\n",
    "        layer = net.layers[lidx]\n",
    "        if count == netWeights.shape[0] and (layer.type != 'BatchNorm' and layer.type != 'Scale'):\n",
    "            print(\"WARNING: no weights left for %s\" % pr)\n",
    "            break\n",
    "        if layer.type == 'Convolution':\n",
    "            print(pr+\"(conv)\")\n",
    "            # bias\n",
    "            if len(net.params[pr]) > 1:\n",
    "                bias_dim = net.params[pr][1].data.shape\n",
    "            else:\n",
    "                bias_dim = (net.params[pr][0].data.shape[0], )\n",
    "            biasSize = np.prod(bias_dim)\n",
    "            conv_bias = np.reshape(netWeights[count:count+biasSize], bias_dim)\n",
    "            if len(net.params[pr]) > 1:\n",
    "                assert(bias_dim == net.params[pr][1].data.shape)\n",
    "                net.params[pr][1].data[...] = conv_bias\n",
    "                conv_bias = None\n",
    "            count = count + biasSize\n",
    "            # batch_norm\n",
    "            next_layer = net.layers[lidx+1]\n",
    "            if next_layer.type == 'BatchNorm':\n",
    "                bn_dims = (3, net.params[pr][0].data.shape[0])\n",
    "                bnSize = np.prod(bn_dims)\n",
    "                batch_norm = np.reshape(netWeights[count:count+bnSize], bn_dims)\n",
    "                count = count + bnSize\n",
    "            # weights\n",
    "            dims = net.params[pr][0].data.shape\n",
    "            weightSize = np.prod(dims)\n",
    "            net.params[pr][0].data[...] = np.reshape(netWeights[count:count+weightSize], dims)\n",
    "            count = count + weightSize\n",
    "        elif layer.type == 'InnerProduct':\n",
    "            print(pr+\"(fc)\")\n",
    "            # bias\n",
    "            biasSize = np.prod(net.params[pr][1].data.shape)\n",
    "            net.params[pr][1].data[...] = np.reshape(netWeights[count:count+biasSize], net.params[pr][1].data.shape)\n",
    "            count = count + biasSize\n",
    "            # weights\n",
    "            dims = net.params[pr][0].data.shape\n",
    "            weightSize = np.prod(dims)\n",
    "            if transFlag:\n",
    "                net.params[pr][0].data[...] = np.reshape(netWeights[count:count+weightSize], (dims[1], dims[0])).transpose()\n",
    "            else:\n",
    "                net.params[pr][0].data[...] = np.reshape(netWeights[count:count+weightSize], dims)\n",
    "            count = count + weightSize\n",
    "        elif layer.type == 'BatchNorm':\n",
    "            print(pr+\"(batchnorm)\")\n",
    "            net.params[pr][0].data[...] = batch_norm[1]\t# mean\n",
    "            net.params[pr][1].data[...] = batch_norm[2]\t# variance\n",
    "            net.params[pr][2].data[...] = 1.0\t# scale factor\n",
    "        elif layer.type == 'Scale':\n",
    "            print(pr+\"(scale)\")\n",
    "            net.params[pr][0].data[...] = batch_norm[0]\t# scale\n",
    "            batch_norm = None\n",
    "            if len(net.params[pr]) > 1:\n",
    "                net.params[pr][1].data[...] = conv_bias\t# bias\n",
    "                conv_bias = None\n",
    "        else:\n",
    "            print(\"WARNING: unsupported layer, \"+pr)\n",
    "    if np.prod(netWeights.shape) != count:\n",
    "        print(\"ERROR: size mismatch: %d\" % count)\n",
    "    net.save(caffemodel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1544cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is ./Data/yolo_train_val.prototxt\n",
      "weight file is ./Data/yolov3.weights\n",
      "caffemodel file is ./Data/yolo_train_val.caffemodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0127 13:35:26.399883  7058 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: ./Data/yolo_train_val.prototxt\n",
      "I0127 13:35:26.399932  7058 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.\n",
      "W0127 13:35:26.399940  7058 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0127 13:35:26.400074  7058 net.cpp:53] Initializing net from parameters: \n",
      "name: \"YOLONet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 448\n",
      "      dim: 448\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 3\n",
      "    kernel_size: 7\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 192\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv6\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv6\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv6\"\n",
      "  top: \"conv6\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool6\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv6\"\n",
      "  top: \"pool6\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv7\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool6\"\n",
      "  top: \"conv7\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv7\"\n",
      "  top: \"conv7\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv8\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv7\"\n",
      "  top: \"conv8\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu8\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv8\"\n",
      "  top: \"conv8\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv9\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv8\"\n",
      "  top: \"conv9\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu9\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv9\"\n",
      "  top: \"conv9\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv10\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv9\"\n",
      "  top: \"conv10\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu10\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv10\"\n",
      "  top: \"conv10\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv11\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv10\"\n",
      "  top: \"conv11\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu11\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv11\"\n",
      "  top: \"conv11\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv12\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv11\"\n",
      "  top: \"conv12\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu12\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv12\"\n",
      "  top: \"conv12\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv13\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv12\"\n",
      "  top: \"conv13\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu13\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv13\"\n",
      "  top: \"conv13\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv14\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv13\"\n",
      "  top: \"conv14\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu14\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv14\"\n",
      "  top: \"conv14\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv15\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv14\"\n",
      "  top: \"conv15\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu15\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv15\"\n",
      "  top: \"conv15\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv16\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv15\"\n",
      "  top: \"conv16\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu16\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv16\"\n",
      "  top: \"conv16\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool16\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv16\"\n",
      "  top: \"pool16\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv17\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool16\"\n",
      "  top: \"conv17\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu17\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv17\"\n",
      "  top: \"conv17\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv18\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv17\"\n",
      "  top: \"conv18\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu18\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv18\"\n",
      "  top: \"conv18\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv19\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv18\"\n",
      "  top: \"conv19\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu19\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv19\"\n",
      "  top: \"conv19\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv20\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv19\"\n",
      "  top: \"conv20\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu20\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv20\"\n",
      "  top: \"conv20\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv21\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv20\"\n",
      "  top: \"conv21\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu21\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv21\"\n",
      "  top: \"conv21\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv22\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv21\"\n",
      "  top: \"conv22\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu22\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv22\"\n",
      "  top: \"conv22\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv23\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv22\"\n",
      "  top: \"conv23\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu23\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv23\"\n",
      "  top: \"conv23\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv24\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv23\"\n",
      "  top: \"conv24\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu24\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv24\"\n",
      "  top: \"conv24\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc25\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"conv24\"\n",
      "  top: \"fc25\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu25\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc25\"\n",
      "  top: \"fc25\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc26\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc25\"\n",
      "  top: \"result\"\n",
      "  inner_product_param {\n",
      "    num_output: 1470\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "I0127 13:35:26.405808  7058 layer_factory.hpp:77] Creating layer input\n",
      "I0127 13:35:26.408123  7058 net.cpp:86] Creating Layer input\n",
      "I0127 13:35:26.408149  7058 net.cpp:382] input -> data\n",
      "I0127 13:35:26.411170  7058 net.cpp:124] Setting up input\n",
      "I0127 13:35:26.411192  7058 net.cpp:131] Top shape: 1 3 448 448 (602112)\n",
      "I0127 13:35:26.411206  7058 net.cpp:139] Memory required for data: 2408448\n",
      "I0127 13:35:26.411213  7058 layer_factory.hpp:77] Creating layer conv1\n",
      "I0127 13:35:26.411334  7058 net.cpp:86] Creating Layer conv1\n",
      "I0127 13:35:26.411345  7058 net.cpp:408] conv1 <- data\n",
      "I0127 13:35:26.411355  7058 net.cpp:382] conv1 -> conv1\n",
      "I0127 13:35:26.413553  7058 net.cpp:124] Setting up conv1\n",
      "I0127 13:35:26.413578  7058 net.cpp:131] Top shape: 1 64 224 224 (3211264)\n",
      "I0127 13:35:26.413592  7058 net.cpp:139] Memory required for data: 15253504\n",
      "I0127 13:35:26.413619  7058 layer_factory.hpp:77] Creating layer relu1\n",
      "I0127 13:35:26.413636  7058 net.cpp:86] Creating Layer relu1\n",
      "I0127 13:35:26.413643  7058 net.cpp:408] relu1 <- conv1\n",
      "I0127 13:35:26.413656  7058 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0127 13:35:26.413683  7058 net.cpp:124] Setting up relu1\n",
      "I0127 13:35:26.413692  7058 net.cpp:131] Top shape: 1 64 224 224 (3211264)\n",
      "I0127 13:35:26.413703  7058 net.cpp:139] Memory required for data: 28098560\n",
      "I0127 13:35:26.413713  7058 layer_factory.hpp:77] Creating layer pool1\n",
      "I0127 13:35:26.413723  7058 net.cpp:86] Creating Layer pool1\n",
      "I0127 13:35:26.413731  7058 net.cpp:408] pool1 <- conv1\n",
      "I0127 13:35:26.413744  7058 net.cpp:382] pool1 -> pool1\n",
      "I0127 13:35:26.413759  7058 net.cpp:124] Setting up pool1\n",
      "I0127 13:35:26.413764  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:35:26.413774  7058 net.cpp:139] Memory required for data: 31309824\n",
      "I0127 13:35:26.413780  7058 layer_factory.hpp:77] Creating layer conv2\n",
      "I0127 13:35:26.413797  7058 net.cpp:86] Creating Layer conv2\n",
      "I0127 13:35:26.413805  7058 net.cpp:408] conv2 <- pool1\n",
      "I0127 13:35:26.413813  7058 net.cpp:382] conv2 -> conv2\n",
      "I0127 13:35:26.417127  7058 net.cpp:124] Setting up conv2\n",
      "I0127 13:35:26.417155  7058 net.cpp:131] Top shape: 1 192 112 112 (2408448)\n",
      "I0127 13:35:26.417173  7058 net.cpp:139] Memory required for data: 40943616\n",
      "I0127 13:35:26.417212  7058 layer_factory.hpp:77] Creating layer relu2\n",
      "I0127 13:35:26.417229  7058 net.cpp:86] Creating Layer relu2\n",
      "I0127 13:35:26.417238  7058 net.cpp:408] relu2 <- conv2\n",
      "I0127 13:35:26.417249  7058 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0127 13:35:26.417261  7058 net.cpp:124] Setting up relu2\n",
      "I0127 13:35:26.417268  7058 net.cpp:131] Top shape: 1 192 112 112 (2408448)\n",
      "I0127 13:35:26.417279  7058 net.cpp:139] Memory required for data: 50577408\n",
      "I0127 13:35:26.417284  7058 layer_factory.hpp:77] Creating layer pool2\n",
      "I0127 13:35:26.417296  7058 net.cpp:86] Creating Layer pool2\n",
      "I0127 13:35:26.417305  7058 net.cpp:408] pool2 <- conv2\n",
      "I0127 13:35:26.417318  7058 net.cpp:382] pool2 -> pool2\n",
      "I0127 13:35:26.417337  7058 net.cpp:124] Setting up pool2\n",
      "I0127 13:35:26.417346  7058 net.cpp:131] Top shape: 1 192 56 56 (602112)\n",
      "I0127 13:35:26.417418  7058 net.cpp:139] Memory required for data: 52985856\n",
      "I0127 13:35:26.417425  7058 layer_factory.hpp:77] Creating layer conv3\n",
      "I0127 13:35:26.417448  7058 net.cpp:86] Creating Layer conv3\n",
      "I0127 13:35:26.417459  7058 net.cpp:408] conv3 <- pool2\n",
      "I0127 13:35:26.417476  7058 net.cpp:382] conv3 -> conv3\n",
      "I0127 13:35:26.418305  7058 net.cpp:124] Setting up conv3\n",
      "I0127 13:35:26.418323  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:35:26.418471  7058 net.cpp:139] Memory required for data: 54591488\n",
      "I0127 13:35:26.418481  7058 layer_factory.hpp:77] Creating layer relu3\n",
      "I0127 13:35:26.418490  7058 net.cpp:86] Creating Layer relu3\n",
      "I0127 13:35:26.418494  7058 net.cpp:408] relu3 <- conv3\n",
      "I0127 13:35:26.418500  7058 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0127 13:35:26.418557  7058 net.cpp:124] Setting up relu3\n",
      "I0127 13:35:26.418586  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:35:26.418613  7058 net.cpp:139] Memory required for data: 56197120\n",
      "I0127 13:35:26.418617  7058 layer_factory.hpp:77] Creating layer conv4\n",
      "I0127 13:35:26.418632  7058 net.cpp:86] Creating Layer conv4\n",
      "I0127 13:35:26.418637  7058 net.cpp:408] conv4 <- conv3\n",
      "I0127 13:35:26.418642  7058 net.cpp:382] conv4 -> conv4\n",
      "I0127 13:35:26.434947  7058 net.cpp:124] Setting up conv4\n",
      "I0127 13:35:26.434967  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:35:26.434978  7058 net.cpp:139] Memory required for data: 59408384\n",
      "I0127 13:35:26.434991  7058 layer_factory.hpp:77] Creating layer relu4\n",
      "I0127 13:35:26.435003  7058 net.cpp:86] Creating Layer relu4\n",
      "I0127 13:35:26.435010  7058 net.cpp:408] relu4 <- conv4\n",
      "I0127 13:35:26.435020  7058 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0127 13:35:26.435032  7058 net.cpp:124] Setting up relu4\n",
      "I0127 13:35:26.435039  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:35:26.435048  7058 net.cpp:139] Memory required for data: 62619648\n",
      "I0127 13:35:26.435055  7058 layer_factory.hpp:77] Creating layer conv5\n",
      "I0127 13:35:26.435067  7058 net.cpp:86] Creating Layer conv5\n",
      "I0127 13:35:26.435075  7058 net.cpp:408] conv5 <- conv4\n",
      "I0127 13:35:26.435083  7058 net.cpp:382] conv5 -> conv5\n",
      "I0127 13:35:26.436756  7058 net.cpp:124] Setting up conv5\n",
      "I0127 13:35:26.436774  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:35:26.436785  7058 net.cpp:139] Memory required for data: 65830912\n",
      "I0127 13:35:26.436803  7058 layer_factory.hpp:77] Creating layer relu5\n",
      "I0127 13:35:26.436817  7058 net.cpp:86] Creating Layer relu5\n",
      "I0127 13:35:26.436825  7058 net.cpp:408] relu5 <- conv5\n",
      "I0127 13:35:26.436834  7058 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0127 13:35:26.436846  7058 net.cpp:124] Setting up relu5\n",
      "I0127 13:35:26.436851  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:35:26.436861  7058 net.cpp:139] Memory required for data: 69042176\n",
      "I0127 13:35:26.436867  7058 layer_factory.hpp:77] Creating layer conv6\n",
      "I0127 13:35:26.436944  7058 net.cpp:86] Creating Layer conv6\n",
      "I0127 13:35:26.436954  7058 net.cpp:408] conv6 <- conv5\n",
      "I0127 13:35:26.436965  7058 net.cpp:382] conv6 -> conv6\n",
      "I0127 13:35:26.473281  7058 net.cpp:124] Setting up conv6\n",
      "I0127 13:35:26.473300  7058 net.cpp:131] Top shape: 1 512 56 56 (1605632)\n",
      "I0127 13:35:26.473317  7058 net.cpp:139] Memory required for data: 75464704\n",
      "I0127 13:35:26.473328  7058 layer_factory.hpp:77] Creating layer relu6\n",
      "I0127 13:35:26.473342  7058 net.cpp:86] Creating Layer relu6\n",
      "I0127 13:35:26.473348  7058 net.cpp:408] relu6 <- conv6\n",
      "I0127 13:35:26.473358  7058 net.cpp:369] relu6 -> conv6 (in-place)\n",
      "I0127 13:35:26.473376  7058 net.cpp:124] Setting up relu6\n",
      "I0127 13:35:26.473381  7058 net.cpp:131] Top shape: 1 512 56 56 (1605632)\n",
      "I0127 13:35:26.473389  7058 net.cpp:139] Memory required for data: 81887232\n",
      "I0127 13:35:26.473394  7058 layer_factory.hpp:77] Creating layer pool6\n",
      "I0127 13:35:26.473402  7058 net.cpp:86] Creating Layer pool6\n",
      "I0127 13:35:26.473405  7058 net.cpp:408] pool6 <- conv6\n",
      "I0127 13:35:26.473417  7058 net.cpp:382] pool6 -> pool6\n",
      "I0127 13:35:26.473434  7058 net.cpp:124] Setting up pool6\n",
      "I0127 13:35:26.473441  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.473449  7058 net.cpp:139] Memory required for data: 83492864\n",
      "I0127 13:35:26.473453  7058 layer_factory.hpp:77] Creating layer conv7\n",
      "I0127 13:35:26.473470  7058 net.cpp:86] Creating Layer conv7\n",
      "I0127 13:35:26.473479  7058 net.cpp:408] conv7 <- pool6\n",
      "I0127 13:35:26.473493  7058 net.cpp:382] conv7 -> conv7\n",
      "I0127 13:35:26.475970  7058 net.cpp:124] Setting up conv7\n",
      "I0127 13:35:26.475983  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.475993  7058 net.cpp:139] Memory required for data: 84295680\n",
      "I0127 13:35:26.476006  7058 layer_factory.hpp:77] Creating layer relu7\n",
      "I0127 13:35:26.476022  7058 net.cpp:86] Creating Layer relu7\n",
      "I0127 13:35:26.476029  7058 net.cpp:408] relu7 <- conv7\n",
      "I0127 13:35:26.476037  7058 net.cpp:369] relu7 -> conv7 (in-place)\n",
      "I0127 13:35:26.476044  7058 net.cpp:124] Setting up relu7\n",
      "I0127 13:35:26.476049  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.476056  7058 net.cpp:139] Memory required for data: 85098496\n",
      "I0127 13:35:26.476063  7058 layer_factory.hpp:77] Creating layer conv8\n",
      "I0127 13:35:26.476075  7058 net.cpp:86] Creating Layer conv8\n",
      "I0127 13:35:26.476080  7058 net.cpp:408] conv8 <- conv7\n",
      "I0127 13:35:26.476087  7058 net.cpp:382] conv8 -> conv8\n",
      "I0127 13:35:26.505272  7058 net.cpp:124] Setting up conv8\n",
      "I0127 13:35:26.505296  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.505309  7058 net.cpp:139] Memory required for data: 86704128\n",
      "I0127 13:35:26.505321  7058 layer_factory.hpp:77] Creating layer relu8\n",
      "I0127 13:35:26.505344  7058 net.cpp:86] Creating Layer relu8\n",
      "I0127 13:35:26.505353  7058 net.cpp:408] relu8 <- conv8\n",
      "I0127 13:35:26.505364  7058 net.cpp:369] relu8 -> conv8 (in-place)\n",
      "I0127 13:35:26.505379  7058 net.cpp:124] Setting up relu8\n",
      "I0127 13:35:26.505388  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.505400  7058 net.cpp:139] Memory required for data: 88309760\n",
      "I0127 13:35:26.505409  7058 layer_factory.hpp:77] Creating layer conv9\n",
      "I0127 13:35:26.505424  7058 net.cpp:86] Creating Layer conv9\n",
      "I0127 13:35:26.505434  7058 net.cpp:408] conv9 <- conv8\n",
      "I0127 13:35:26.505445  7058 net.cpp:382] conv9 -> conv9\n",
      "I0127 13:35:26.507844  7058 net.cpp:124] Setting up conv9\n",
      "I0127 13:35:26.507864  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.507895  7058 net.cpp:139] Memory required for data: 89112576\n",
      "I0127 13:35:26.507911  7058 layer_factory.hpp:77] Creating layer relu9\n",
      "I0127 13:35:26.507923  7058 net.cpp:86] Creating Layer relu9\n",
      "I0127 13:35:26.507931  7058 net.cpp:408] relu9 <- conv9\n",
      "I0127 13:35:26.507941  7058 net.cpp:369] relu9 -> conv9 (in-place)\n",
      "I0127 13:35:26.507953  7058 net.cpp:124] Setting up relu9\n",
      "I0127 13:35:26.507959  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.507969  7058 net.cpp:139] Memory required for data: 89915392\n",
      "I0127 13:35:26.507977  7058 layer_factory.hpp:77] Creating layer conv10\n",
      "I0127 13:35:26.507988  7058 net.cpp:86] Creating Layer conv10\n",
      "I0127 13:35:26.507995  7058 net.cpp:408] conv10 <- conv9\n",
      "I0127 13:35:26.508005  7058 net.cpp:382] conv10 -> conv10\n",
      "I0127 13:35:26.527792  7058 net.cpp:124] Setting up conv10\n",
      "I0127 13:35:26.527809  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.527828  7058 net.cpp:139] Memory required for data: 91521024\n",
      "I0127 13:35:26.527840  7058 layer_factory.hpp:77] Creating layer relu10\n",
      "I0127 13:35:26.527849  7058 net.cpp:86] Creating Layer relu10\n",
      "I0127 13:35:26.527858  7058 net.cpp:408] relu10 <- conv10\n",
      "I0127 13:35:26.527866  7058 net.cpp:369] relu10 -> conv10 (in-place)\n",
      "I0127 13:35:26.527874  7058 net.cpp:124] Setting up relu10\n",
      "I0127 13:35:26.527879  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.527892  7058 net.cpp:139] Memory required for data: 93126656\n",
      "I0127 13:35:26.527902  7058 layer_factory.hpp:77] Creating layer conv11\n",
      "I0127 13:35:26.527913  7058 net.cpp:86] Creating Layer conv11\n",
      "I0127 13:35:26.527918  7058 net.cpp:408] conv11 <- conv10\n",
      "I0127 13:35:26.527926  7058 net.cpp:382] conv11 -> conv11\n",
      "I0127 13:35:26.532801  7058 net.cpp:124] Setting up conv11\n",
      "I0127 13:35:26.532824  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.532847  7058 net.cpp:139] Memory required for data: 93929472\n",
      "I0127 13:35:26.532864  7058 layer_factory.hpp:77] Creating layer relu11\n",
      "I0127 13:35:26.532900  7058 net.cpp:86] Creating Layer relu11\n",
      "I0127 13:35:26.532912  7058 net.cpp:408] relu11 <- conv11\n",
      "I0127 13:35:26.532924  7058 net.cpp:369] relu11 -> conv11 (in-place)\n",
      "I0127 13:35:26.532938  7058 net.cpp:124] Setting up relu11\n",
      "I0127 13:35:26.532949  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.532969  7058 net.cpp:139] Memory required for data: 94732288\n",
      "I0127 13:35:26.532979  7058 layer_factory.hpp:77] Creating layer conv12\n",
      "I0127 13:35:26.532997  7058 net.cpp:86] Creating Layer conv12\n",
      "I0127 13:35:26.533005  7058 net.cpp:408] conv12 <- conv11\n",
      "I0127 13:35:26.533017  7058 net.cpp:382] conv12 -> conv12\n",
      "I0127 13:35:26.554899  7058 net.cpp:124] Setting up conv12\n",
      "I0127 13:35:26.554920  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.554935  7058 net.cpp:139] Memory required for data: 96337920\n",
      "I0127 13:35:26.554948  7058 layer_factory.hpp:77] Creating layer relu12\n",
      "I0127 13:35:26.554965  7058 net.cpp:86] Creating Layer relu12\n",
      "I0127 13:35:26.555008  7058 net.cpp:408] relu12 <- conv12\n",
      "I0127 13:35:26.555075  7058 net.cpp:369] relu12 -> conv12 (in-place)\n",
      "I0127 13:35:26.555088  7058 net.cpp:124] Setting up relu12\n",
      "I0127 13:35:26.555094  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.555101  7058 net.cpp:139] Memory required for data: 97943552\n",
      "I0127 13:35:26.555106  7058 layer_factory.hpp:77] Creating layer conv13\n",
      "I0127 13:35:26.555119  7058 net.cpp:86] Creating Layer conv13\n",
      "I0127 13:35:26.555125  7058 net.cpp:408] conv13 <- conv12\n",
      "I0127 13:35:26.555140  7058 net.cpp:382] conv13 -> conv13\n",
      "I0127 13:35:26.557353  7058 net.cpp:124] Setting up conv13\n",
      "I0127 13:35:26.557377  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.557387  7058 net.cpp:139] Memory required for data: 98746368\n",
      "I0127 13:35:26.557404  7058 layer_factory.hpp:77] Creating layer relu13\n",
      "I0127 13:35:26.557416  7058 net.cpp:86] Creating Layer relu13\n",
      "I0127 13:35:26.557423  7058 net.cpp:408] relu13 <- conv13\n",
      "I0127 13:35:26.557432  7058 net.cpp:369] relu13 -> conv13 (in-place)\n",
      "I0127 13:35:26.557442  7058 net.cpp:124] Setting up relu13\n",
      "I0127 13:35:26.557449  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:35:26.557461  7058 net.cpp:139] Memory required for data: 99549184\n",
      "I0127 13:35:26.557467  7058 layer_factory.hpp:77] Creating layer conv14\n",
      "I0127 13:35:26.557483  7058 net.cpp:86] Creating Layer conv14\n",
      "I0127 13:35:26.557495  7058 net.cpp:408] conv14 <- conv13\n",
      "I0127 13:35:26.557507  7058 net.cpp:382] conv14 -> conv14\n",
      "I0127 13:35:26.577908  7058 net.cpp:124] Setting up conv14\n",
      "I0127 13:35:26.577936  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.577951  7058 net.cpp:139] Memory required for data: 101154816\n",
      "I0127 13:35:26.577963  7058 layer_factory.hpp:77] Creating layer relu14\n",
      "I0127 13:35:26.577976  7058 net.cpp:86] Creating Layer relu14\n",
      "I0127 13:35:26.577992  7058 net.cpp:408] relu14 <- conv14\n",
      "I0127 13:35:26.578013  7058 net.cpp:369] relu14 -> conv14 (in-place)\n",
      "I0127 13:35:26.578032  7058 net.cpp:124] Setting up relu14\n",
      "I0127 13:35:26.578039  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.578050  7058 net.cpp:139] Memory required for data: 102760448\n",
      "I0127 13:35:26.578058  7058 layer_factory.hpp:77] Creating layer conv15\n",
      "I0127 13:35:26.578075  7058 net.cpp:86] Creating Layer conv15\n",
      "I0127 13:35:26.578083  7058 net.cpp:408] conv15 <- conv14\n",
      "I0127 13:35:26.578092  7058 net.cpp:382] conv15 -> conv15\n",
      "I0127 13:35:26.597601  7058 net.cpp:124] Setting up conv15\n",
      "I0127 13:35:26.597620  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.597632  7058 net.cpp:139] Memory required for data: 104366080\n",
      "I0127 13:35:26.597649  7058 layer_factory.hpp:77] Creating layer relu15\n",
      "I0127 13:35:26.597671  7058 net.cpp:86] Creating Layer relu15\n",
      "I0127 13:35:26.597679  7058 net.cpp:408] relu15 <- conv15\n",
      "I0127 13:35:26.597689  7058 net.cpp:369] relu15 -> conv15 (in-place)\n",
      "I0127 13:35:26.597700  7058 net.cpp:124] Setting up relu15\n",
      "I0127 13:35:26.597707  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:35:26.597716  7058 net.cpp:139] Memory required for data: 105971712\n",
      "I0127 13:35:26.597723  7058 layer_factory.hpp:77] Creating layer conv16\n",
      "I0127 13:35:26.597738  7058 net.cpp:86] Creating Layer conv16\n",
      "I0127 13:35:26.597751  7058 net.cpp:408] conv16 <- conv15\n",
      "I0127 13:35:26.597762  7058 net.cpp:382] conv16 -> conv16\n",
      "I0127 13:35:26.668977  7058 net.cpp:124] Setting up conv16\n",
      "I0127 13:35:26.669005  7058 net.cpp:131] Top shape: 1 1024 28 28 (802816)\n",
      "I0127 13:35:26.669019  7058 net.cpp:139] Memory required for data: 109182976\n",
      "I0127 13:35:26.669032  7058 layer_factory.hpp:77] Creating layer relu16\n",
      "I0127 13:35:26.669049  7058 net.cpp:86] Creating Layer relu16\n",
      "I0127 13:35:26.669057  7058 net.cpp:408] relu16 <- conv16\n",
      "I0127 13:35:26.669067  7058 net.cpp:369] relu16 -> conv16 (in-place)\n",
      "I0127 13:35:26.669083  7058 net.cpp:124] Setting up relu16\n",
      "I0127 13:35:26.669095  7058 net.cpp:131] Top shape: 1 1024 28 28 (802816)\n",
      "I0127 13:35:26.669106  7058 net.cpp:139] Memory required for data: 112394240\n",
      "I0127 13:35:26.669111  7058 layer_factory.hpp:77] Creating layer pool16\n",
      "I0127 13:35:26.669121  7058 net.cpp:86] Creating Layer pool16\n",
      "I0127 13:35:26.669127  7058 net.cpp:408] pool16 <- conv16\n",
      "I0127 13:35:26.669137  7058 net.cpp:382] pool16 -> pool16\n",
      "I0127 13:35:26.669152  7058 net.cpp:124] Setting up pool16\n",
      "I0127 13:35:26.669158  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.669189  7058 net.cpp:139] Memory required for data: 113197056\n",
      "I0127 13:35:26.669201  7058 layer_factory.hpp:77] Creating layer conv17\n",
      "I0127 13:35:26.669219  7058 net.cpp:86] Creating Layer conv17\n",
      "I0127 13:35:26.669226  7058 net.cpp:408] conv17 <- pool16\n",
      "I0127 13:35:26.669235  7058 net.cpp:382] conv17 -> conv17\n",
      "I0127 13:35:26.677814  7058 net.cpp:124] Setting up conv17\n",
      "I0127 13:35:26.677832  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:35:26.677850  7058 net.cpp:139] Memory required for data: 113598464\n",
      "I0127 13:35:26.677872  7058 layer_factory.hpp:77] Creating layer relu17\n",
      "I0127 13:35:26.677887  7058 net.cpp:86] Creating Layer relu17\n",
      "I0127 13:35:26.677896  7058 net.cpp:408] relu17 <- conv17\n",
      "I0127 13:35:26.677906  7058 net.cpp:369] relu17 -> conv17 (in-place)\n",
      "I0127 13:35:26.677917  7058 net.cpp:124] Setting up relu17\n",
      "I0127 13:35:26.677923  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:35:26.677933  7058 net.cpp:139] Memory required for data: 113999872\n",
      "I0127 13:35:26.677942  7058 layer_factory.hpp:77] Creating layer conv18\n",
      "I0127 13:35:26.678005  7058 net.cpp:86] Creating Layer conv18\n",
      "I0127 13:35:26.678020  7058 net.cpp:408] conv18 <- conv17\n",
      "I0127 13:35:26.678071  7058 net.cpp:382] conv18 -> conv18\n",
      "I0127 13:35:26.753333  7058 net.cpp:124] Setting up conv18\n",
      "I0127 13:35:26.753355  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.753368  7058 net.cpp:139] Memory required for data: 114802688\n",
      "I0127 13:35:26.753381  7058 layer_factory.hpp:77] Creating layer relu18\n",
      "I0127 13:35:26.753398  7058 net.cpp:86] Creating Layer relu18\n",
      "I0127 13:35:26.753417  7058 net.cpp:408] relu18 <- conv18\n",
      "I0127 13:35:26.753427  7058 net.cpp:369] relu18 -> conv18 (in-place)\n",
      "I0127 13:35:26.753439  7058 net.cpp:124] Setting up relu18\n",
      "I0127 13:35:26.753445  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.753456  7058 net.cpp:139] Memory required for data: 115605504\n",
      "I0127 13:35:26.753463  7058 layer_factory.hpp:77] Creating layer conv19\n",
      "I0127 13:35:26.753480  7058 net.cpp:86] Creating Layer conv19\n",
      "I0127 13:35:26.753489  7058 net.cpp:408] conv19 <- conv18\n",
      "I0127 13:35:26.753502  7058 net.cpp:382] conv19 -> conv19\n",
      "I0127 13:35:26.762746  7058 net.cpp:124] Setting up conv19\n",
      "I0127 13:35:26.762770  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:35:26.762789  7058 net.cpp:139] Memory required for data: 116006912\n",
      "I0127 13:35:26.762799  7058 layer_factory.hpp:77] Creating layer relu19\n",
      "I0127 13:35:26.762809  7058 net.cpp:86] Creating Layer relu19\n",
      "I0127 13:35:26.762820  7058 net.cpp:408] relu19 <- conv19\n",
      "I0127 13:35:26.762835  7058 net.cpp:369] relu19 -> conv19 (in-place)\n",
      "I0127 13:35:26.762845  7058 net.cpp:124] Setting up relu19\n",
      "I0127 13:35:26.762850  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:35:26.762858  7058 net.cpp:139] Memory required for data: 116408320\n",
      "I0127 13:35:26.762863  7058 layer_factory.hpp:77] Creating layer conv20\n",
      "I0127 13:35:26.762925  7058 net.cpp:86] Creating Layer conv20\n",
      "I0127 13:35:26.762938  7058 net.cpp:408] conv20 <- conv19\n",
      "I0127 13:35:26.762954  7058 net.cpp:382] conv20 -> conv20\n",
      "I0127 13:35:26.841461  7058 net.cpp:124] Setting up conv20\n",
      "I0127 13:35:26.841493  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.841508  7058 net.cpp:139] Memory required for data: 117211136\n",
      "I0127 13:35:26.841521  7058 layer_factory.hpp:77] Creating layer relu20\n",
      "I0127 13:35:26.841534  7058 net.cpp:86] Creating Layer relu20\n",
      "I0127 13:35:26.841544  7058 net.cpp:408] relu20 <- conv20\n",
      "I0127 13:35:26.841554  7058 net.cpp:369] relu20 -> conv20 (in-place)\n",
      "I0127 13:35:26.841568  7058 net.cpp:124] Setting up relu20\n",
      "I0127 13:35:26.841580  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.841590  7058 net.cpp:139] Memory required for data: 118013952\n",
      "I0127 13:35:26.841598  7058 layer_factory.hpp:77] Creating layer conv21\n",
      "I0127 13:35:26.841609  7058 net.cpp:86] Creating Layer conv21\n",
      "I0127 13:35:26.841616  7058 net.cpp:408] conv21 <- conv20\n",
      "I0127 13:35:26.841626  7058 net.cpp:382] conv21 -> conv21\n",
      "I0127 13:35:26.982313  7058 net.cpp:124] Setting up conv21\n",
      "I0127 13:35:26.982353  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.982368  7058 net.cpp:139] Memory required for data: 118816768\n",
      "I0127 13:35:26.982380  7058 layer_factory.hpp:77] Creating layer relu21\n",
      "I0127 13:35:26.982405  7058 net.cpp:86] Creating Layer relu21\n",
      "I0127 13:35:26.982414  7058 net.cpp:408] relu21 <- conv21\n",
      "I0127 13:35:26.982422  7058 net.cpp:369] relu21 -> conv21 (in-place)\n",
      "I0127 13:35:26.982434  7058 net.cpp:124] Setting up relu21\n",
      "I0127 13:35:26.982441  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:35:26.982457  7058 net.cpp:139] Memory required for data: 119619584\n",
      "I0127 13:35:26.982465  7058 layer_factory.hpp:77] Creating layer conv22\n",
      "I0127 13:35:26.982481  7058 net.cpp:86] Creating Layer conv22\n",
      "I0127 13:35:26.982537  7058 net.cpp:408] conv22 <- conv21\n",
      "I0127 13:35:26.982558  7058 net.cpp:382] conv22 -> conv22\n",
      "I0127 13:35:27.137641  7058 net.cpp:124] Setting up conv22\n",
      "I0127 13:35:27.137672  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.137689  7058 net.cpp:139] Memory required for data: 119820288\n",
      "I0127 13:35:27.137717  7058 layer_factory.hpp:77] Creating layer relu22\n",
      "I0127 13:35:27.137743  7058 net.cpp:86] Creating Layer relu22\n",
      "I0127 13:35:27.137751  7058 net.cpp:408] relu22 <- conv22\n",
      "I0127 13:35:27.137763  7058 net.cpp:369] relu22 -> conv22 (in-place)\n",
      "I0127 13:35:27.137787  7058 net.cpp:124] Setting up relu22\n",
      "I0127 13:35:27.137794  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.137810  7058 net.cpp:139] Memory required for data: 120020992\n",
      "I0127 13:35:27.137817  7058 layer_factory.hpp:77] Creating layer conv23\n",
      "I0127 13:35:27.137830  7058 net.cpp:86] Creating Layer conv23\n",
      "I0127 13:35:27.137836  7058 net.cpp:408] conv23 <- conv22\n",
      "I0127 13:35:27.137846  7058 net.cpp:382] conv23 -> conv23\n",
      "I0127 13:35:27.293023  7058 net.cpp:124] Setting up conv23\n",
      "I0127 13:35:27.293045  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.293108  7058 net.cpp:139] Memory required for data: 120221696\n",
      "I0127 13:35:27.293128  7058 layer_factory.hpp:77] Creating layer relu23\n",
      "I0127 13:35:27.293141  7058 net.cpp:86] Creating Layer relu23\n",
      "I0127 13:35:27.293149  7058 net.cpp:408] relu23 <- conv23\n",
      "I0127 13:35:27.293159  7058 net.cpp:369] relu23 -> conv23 (in-place)\n",
      "I0127 13:35:27.293172  7058 net.cpp:124] Setting up relu23\n",
      "I0127 13:35:27.293179  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.293190  7058 net.cpp:139] Memory required for data: 120422400\n",
      "I0127 13:35:27.293197  7058 layer_factory.hpp:77] Creating layer conv24\n",
      "I0127 13:35:27.293215  7058 net.cpp:86] Creating Layer conv24\n",
      "I0127 13:35:27.293222  7058 net.cpp:408] conv24 <- conv23\n",
      "I0127 13:35:27.293246  7058 net.cpp:382] conv24 -> conv24\n",
      "I0127 13:35:27.440187  7058 net.cpp:124] Setting up conv24\n",
      "I0127 13:35:27.440207  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.440222  7058 net.cpp:139] Memory required for data: 120623104\n",
      "I0127 13:35:27.440238  7058 layer_factory.hpp:77] Creating layer relu24\n",
      "I0127 13:35:27.440253  7058 net.cpp:86] Creating Layer relu24\n",
      "I0127 13:35:27.440259  7058 net.cpp:408] relu24 <- conv24\n",
      "I0127 13:35:27.440266  7058 net.cpp:369] relu24 -> conv24 (in-place)\n",
      "I0127 13:35:27.440275  7058 net.cpp:124] Setting up relu24\n",
      "I0127 13:35:27.440280  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:35:27.440289  7058 net.cpp:139] Memory required for data: 120823808\n",
      "I0127 13:35:27.440294  7058 layer_factory.hpp:77] Creating layer fc25\n",
      "I0127 13:35:27.440304  7058 net.cpp:86] Creating Layer fc25\n",
      "I0127 13:35:27.440313  7058 net.cpp:408] fc25 <- conv24\n",
      "I0127 13:35:27.440326  7058 net.cpp:382] fc25 -> fc25\n",
      "I0127 13:35:30.695915  7058 net.cpp:124] Setting up fc25\n",
      "I0127 13:35:30.695942  7058 net.cpp:131] Top shape: 1 4096 (4096)\n",
      "I0127 13:35:30.695953  7058 net.cpp:139] Memory required for data: 120840192\n",
      "I0127 13:35:30.695966  7058 layer_factory.hpp:77] Creating layer relu25\n",
      "I0127 13:35:30.695979  7058 net.cpp:86] Creating Layer relu25\n",
      "I0127 13:35:30.695987  7058 net.cpp:408] relu25 <- fc25\n",
      "I0127 13:35:30.695997  7058 net.cpp:369] relu25 -> fc25 (in-place)\n",
      "I0127 13:35:30.696015  7058 net.cpp:124] Setting up relu25\n",
      "I0127 13:35:30.696024  7058 net.cpp:131] Top shape: 1 4096 (4096)\n",
      "I0127 13:35:30.696033  7058 net.cpp:139] Memory required for data: 120856576\n",
      "I0127 13:35:30.696040  7058 layer_factory.hpp:77] Creating layer fc26\n",
      "I0127 13:35:30.696053  7058 net.cpp:86] Creating Layer fc26\n",
      "I0127 13:35:30.696060  7058 net.cpp:408] fc26 <- fc25\n",
      "I0127 13:35:30.696069  7058 net.cpp:382] fc26 -> result\n",
      "I0127 13:35:30.785742  7058 net.cpp:124] Setting up fc26\n",
      "I0127 13:35:30.785763  7058 net.cpp:131] Top shape: 1 1470 (1470)\n",
      "I0127 13:35:30.785773  7058 net.cpp:139] Memory required for data: 120862456\n",
      "I0127 13:35:30.785784  7058 net.cpp:202] fc26 does not need backward computation.\n",
      "I0127 13:35:30.785791  7058 net.cpp:202] relu25 does not need backward computation.\n",
      "I0127 13:35:30.785797  7058 net.cpp:202] fc25 does not need backward computation.\n",
      "I0127 13:35:30.785804  7058 net.cpp:202] relu24 does not need backward computation.\n",
      "I0127 13:35:30.785810  7058 net.cpp:202] conv24 does not need backward computation.\n",
      "I0127 13:35:30.785818  7058 net.cpp:202] relu23 does not need backward computation.\n",
      "I0127 13:35:30.785825  7058 net.cpp:202] conv23 does not need backward computation.\n",
      "I0127 13:35:30.785836  7058 net.cpp:202] relu22 does not need backward computation.\n",
      "I0127 13:35:30.785845  7058 net.cpp:202] conv22 does not need backward computation.\n",
      "I0127 13:35:30.785857  7058 net.cpp:202] relu21 does not need backward computation.\n",
      "I0127 13:35:30.785863  7058 net.cpp:202] conv21 does not need backward computation.\n",
      "I0127 13:35:30.785868  7058 net.cpp:202] relu20 does not need backward computation.\n",
      "I0127 13:35:30.785909  7058 net.cpp:202] conv20 does not need backward computation.\n",
      "I0127 13:35:30.785917  7058 net.cpp:202] relu19 does not need backward computation.\n",
      "I0127 13:35:30.785923  7058 net.cpp:202] conv19 does not need backward computation.\n",
      "I0127 13:35:30.785928  7058 net.cpp:202] relu18 does not need backward computation.\n",
      "I0127 13:35:30.785933  7058 net.cpp:202] conv18 does not need backward computation.\n",
      "I0127 13:35:30.785938  7058 net.cpp:202] relu17 does not need backward computation.\n",
      "I0127 13:35:30.785943  7058 net.cpp:202] conv17 does not need backward computation.\n",
      "I0127 13:35:30.785952  7058 net.cpp:202] pool16 does not need backward computation.\n",
      "I0127 13:35:30.785962  7058 net.cpp:202] relu16 does not need backward computation.\n",
      "I0127 13:35:30.785971  7058 net.cpp:202] conv16 does not need backward computation.\n",
      "I0127 13:35:30.785976  7058 net.cpp:202] relu15 does not need backward computation.\n",
      "I0127 13:35:30.785981  7058 net.cpp:202] conv15 does not need backward computation.\n",
      "I0127 13:35:30.785986  7058 net.cpp:202] relu14 does not need backward computation.\n",
      "I0127 13:35:30.785991  7058 net.cpp:202] conv14 does not need backward computation.\n",
      "I0127 13:35:30.785996  7058 net.cpp:202] relu13 does not need backward computation.\n",
      "I0127 13:35:30.786002  7058 net.cpp:202] conv13 does not need backward computation.\n",
      "I0127 13:35:30.786013  7058 net.cpp:202] relu12 does not need backward computation.\n",
      "I0127 13:35:30.786024  7058 net.cpp:202] conv12 does not need backward computation.\n",
      "I0127 13:35:30.786031  7058 net.cpp:202] relu11 does not need backward computation.\n",
      "I0127 13:35:30.786036  7058 net.cpp:202] conv11 does not need backward computation.\n",
      "I0127 13:35:30.786042  7058 net.cpp:202] relu10 does not need backward computation.\n",
      "I0127 13:35:30.786047  7058 net.cpp:202] conv10 does not need backward computation.\n",
      "I0127 13:35:30.786052  7058 net.cpp:202] relu9 does not need backward computation.\n",
      "I0127 13:35:30.786058  7058 net.cpp:202] conv9 does not need backward computation.\n",
      "I0127 13:35:30.786069  7058 net.cpp:202] relu8 does not need backward computation.\n",
      "I0127 13:35:30.786080  7058 net.cpp:202] conv8 does not need backward computation.\n",
      "I0127 13:35:30.786087  7058 net.cpp:202] relu7 does not need backward computation.\n",
      "I0127 13:35:30.786092  7058 net.cpp:202] conv7 does not need backward computation.\n",
      "I0127 13:35:30.786096  7058 net.cpp:202] pool6 does not need backward computation.\n",
      "I0127 13:35:30.786101  7058 net.cpp:202] relu6 does not need backward computation.\n",
      "I0127 13:35:30.786106  7058 net.cpp:202] conv6 does not need backward computation.\n",
      "I0127 13:35:30.786111  7058 net.cpp:202] relu5 does not need backward computation.\n",
      "I0127 13:35:30.786120  7058 net.cpp:202] conv5 does not need backward computation.\n",
      "I0127 13:35:30.786129  7058 net.cpp:202] relu4 does not need backward computation.\n",
      "I0127 13:35:30.786140  7058 net.cpp:202] conv4 does not need backward computation.\n",
      "I0127 13:35:30.786146  7058 net.cpp:202] relu3 does not need backward computation.\n",
      "I0127 13:35:30.786151  7058 net.cpp:202] conv3 does not need backward computation.\n",
      "I0127 13:35:30.786156  7058 net.cpp:202] pool2 does not need backward computation.\n",
      "I0127 13:35:30.786162  7058 net.cpp:202] relu2 does not need backward computation.\n",
      "I0127 13:35:30.786167  7058 net.cpp:202] conv2 does not need backward computation.\n",
      "I0127 13:35:30.786176  7058 net.cpp:202] pool1 does not need backward computation.\n",
      "I0127 13:35:30.786185  7058 net.cpp:202] relu1 does not need backward computation.\n",
      "I0127 13:35:30.786195  7058 net.cpp:202] conv1 does not need backward computation.\n",
      "I0127 13:35:30.786201  7058 net.cpp:202] input does not need backward computation.\n",
      "I0127 13:35:30.786206  7058 net.cpp:244] This network produces output result\n",
      "I0127 13:35:30.786252  7058 net.cpp:257] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(62001758,)\n",
      "conv1(conv)\n",
      "conv2(conv)\n",
      "conv3(conv)\n",
      "conv4(conv)\n",
      "conv5(conv)\n",
      "conv6(conv)\n",
      "conv7(conv)\n",
      "conv8(conv)\n",
      "conv9(conv)\n",
      "conv10(conv)\n",
      "conv11(conv)\n",
      "conv12(conv)\n",
      "conv13(conv)\n",
      "conv14(conv)\n",
      "conv15(conv)\n",
      "conv16(conv)\n",
      "conv17(conv)\n",
      "conv18(conv)\n",
      "conv19(conv)\n",
      "conv20(conv)\n",
      "conv21(conv)\n",
      "conv22(conv)\n",
      "conv23(conv)\n",
      "conv24(conv)\n",
      "fc25(fc)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1841694 into shape (4096,50176)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgencaffemodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myoloweight_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaffemodel_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mgencaffemodel\u001b[0;34m(model_filename, yoloweight_filename, caffemodel_filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m         net\u001b[38;5;241m.\u001b[39mparams[pr][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(netWeights[count:count\u001b[38;5;241m+\u001b[39mweightSize], (dims[\u001b[38;5;241m1\u001b[39m], dims[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m         net\u001b[38;5;241m.\u001b[39mparams[pr][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetWeights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mweightSize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m weightSize\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:301\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:61\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1841694 into shape (4096,50176)"
     ]
    }
   ],
   "source": [
    "gencaffemodel(model_filename, yoloweight_filename, caffemodel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb1f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is ./Data/yolo_small_train_val.prototxt\n",
      "weight file is ./Data/yolov3.weights\n",
      "caffemodel file is ./Data/yolo_small_train_val.caffemodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0127 13:36:00.274158  7058 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: ./Data/yolo_small_train_val.prototxt\n",
      "I0127 13:36:00.274188  7058 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.\n",
      "W0127 13:36:00.274194  7058 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0127 13:36:00.274341  7058 net.cpp:53] Initializing net from parameters: \n",
      "name: \"YOLONet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 448\n",
      "      dim: 448\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 3\n",
      "    kernel_size: 7\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 192\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv6\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv6\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv6\"\n",
      "  top: \"conv6\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool6\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv6\"\n",
      "  top: \"pool6\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv7\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool6\"\n",
      "  top: \"conv7\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv7\"\n",
      "  top: \"conv7\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv8\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv7\"\n",
      "  top: \"conv8\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu8\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv8\"\n",
      "  top: \"conv8\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv9\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv8\"\n",
      "  top: \"conv9\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu9\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv9\"\n",
      "  top: \"conv9\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv10\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv9\"\n",
      "  top: \"conv10\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu10\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv10\"\n",
      "  top: \"conv10\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv11\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv10\"\n",
      "  top: \"conv11\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu11\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv11\"\n",
      "  top: \"conv11\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv12\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv11\"\n",
      "  top: \"conv12\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu12\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv12\"\n",
      "  top: \"conv12\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv13\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv12\"\n",
      "  top: \"conv13\"\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu13\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv13\"\n",
      "  top: \"conv13\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv14\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv13\"\n",
      "  top: \"conv14\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu14\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv14\"\n",
      "  top: \"conv14\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv15\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv14\"\n",
      "  top: \"conv15\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu15\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv15\"\n",
      "  top: \"conv15\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv16\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv15\"\n",
      "  top: \"conv16\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu16\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv16\"\n",
      "  top: \"conv16\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool16\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv16\"\n",
      "  top: \"pool16\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv17\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool16\"\n",
      "  top: \"conv17\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu17\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv17\"\n",
      "  top: \"conv17\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv18\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv17\"\n",
      "  top: \"conv18\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu18\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv18\"\n",
      "  top: \"conv18\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv19\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv18\"\n",
      "  top: \"conv19\"\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    pad: 0\n",
      "    kernel_size: 1\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu19\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv19\"\n",
      "  top: \"conv19\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv20\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv19\"\n",
      "  top: \"conv20\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu20\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv20\"\n",
      "  top: \"conv20\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv21\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv20\"\n",
      "  top: \"conv21\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu21\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv21\"\n",
      "  top: \"conv21\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv22\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv21\"\n",
      "  top: \"conv22\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu22\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv22\"\n",
      "  top: \"conv22\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv23\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv22\"\n",
      "  top: \"conv23\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu23\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv23\"\n",
      "  top: \"conv23\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv24\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv23\"\n",
      "  top: \"conv24\"\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu24\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv24\"\n",
      "  top: \"conv24\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc25\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"conv24\"\n",
      "  top: \"fc25\"\n",
      "  inner_product_param {\n",
      "    num_output: 512\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu25\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc25\"\n",
      "  top: \"fc25\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc26\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc25\"\n",
      "  top: \"fc26\"\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu26\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc26\"\n",
      "  top: \"fc26\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc27\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc26\"\n",
      "  top: \"result\"\n",
      "  inner_product_param {\n",
      "    num_output: 1470\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "I0127 13:36:00.275279  7058 layer_factory.hpp:77] Creating layer input\n",
      "I0127 13:36:00.275300  7058 net.cpp:86] Creating Layer input\n",
      "I0127 13:36:00.275311  7058 net.cpp:382] input -> data\n",
      "I0127 13:36:00.275323  7058 net.cpp:124] Setting up input\n",
      "I0127 13:36:00.275328  7058 net.cpp:131] Top shape: 1 3 448 448 (602112)\n",
      "I0127 13:36:00.275337  7058 net.cpp:139] Memory required for data: 2408448\n",
      "I0127 13:36:00.275344  7058 layer_factory.hpp:77] Creating layer conv1\n",
      "I0127 13:36:00.275354  7058 net.cpp:86] Creating Layer conv1\n",
      "I0127 13:36:00.275359  7058 net.cpp:408] conv1 <- data\n",
      "I0127 13:36:00.275367  7058 net.cpp:382] conv1 -> conv1\n",
      "I0127 13:36:00.275501  7058 net.cpp:124] Setting up conv1\n",
      "I0127 13:36:00.275509  7058 net.cpp:131] Top shape: 1 64 224 224 (3211264)\n",
      "I0127 13:36:00.275517  7058 net.cpp:139] Memory required for data: 15253504\n",
      "I0127 13:36:00.275528  7058 layer_factory.hpp:77] Creating layer relu1\n",
      "I0127 13:36:00.275537  7058 net.cpp:86] Creating Layer relu1\n",
      "I0127 13:36:00.275542  7058 net.cpp:408] relu1 <- conv1\n",
      "I0127 13:36:00.275548  7058 net.cpp:369] relu1 -> conv1 (in-place)\n",
      "I0127 13:36:00.275557  7058 net.cpp:124] Setting up relu1\n",
      "I0127 13:36:00.275565  7058 net.cpp:131] Top shape: 1 64 224 224 (3211264)\n",
      "I0127 13:36:00.275580  7058 net.cpp:139] Memory required for data: 28098560\n",
      "I0127 13:36:00.275586  7058 layer_factory.hpp:77] Creating layer pool1\n",
      "I0127 13:36:00.275593  7058 net.cpp:86] Creating Layer pool1\n",
      "I0127 13:36:00.275597  7058 net.cpp:408] pool1 <- conv1\n",
      "I0127 13:36:00.275604  7058 net.cpp:382] pool1 -> pool1\n",
      "I0127 13:36:00.275614  7058 net.cpp:124] Setting up pool1\n",
      "I0127 13:36:00.275619  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:36:00.275627  7058 net.cpp:139] Memory required for data: 31309824\n",
      "I0127 13:36:00.275632  7058 layer_factory.hpp:77] Creating layer conv2\n",
      "I0127 13:36:00.275641  7058 net.cpp:86] Creating Layer conv2\n",
      "I0127 13:36:00.275646  7058 net.cpp:408] conv2 <- pool1\n",
      "I0127 13:36:00.275712  7058 net.cpp:382] conv2 -> conv2\n",
      "I0127 13:36:00.277339  7058 net.cpp:124] Setting up conv2\n",
      "I0127 13:36:00.277354  7058 net.cpp:131] Top shape: 1 192 112 112 (2408448)\n",
      "I0127 13:36:00.277370  7058 net.cpp:139] Memory required for data: 40943616\n",
      "I0127 13:36:00.277386  7058 layer_factory.hpp:77] Creating layer relu2\n",
      "I0127 13:36:00.277397  7058 net.cpp:86] Creating Layer relu2\n",
      "I0127 13:36:00.277405  7058 net.cpp:408] relu2 <- conv2\n",
      "I0127 13:36:00.277415  7058 net.cpp:369] relu2 -> conv2 (in-place)\n",
      "I0127 13:36:00.277424  7058 net.cpp:124] Setting up relu2\n",
      "I0127 13:36:00.277431  7058 net.cpp:131] Top shape: 1 192 112 112 (2408448)\n",
      "I0127 13:36:00.277441  7058 net.cpp:139] Memory required for data: 50577408\n",
      "I0127 13:36:00.277448  7058 layer_factory.hpp:77] Creating layer pool2\n",
      "I0127 13:36:00.277463  7058 net.cpp:86] Creating Layer pool2\n",
      "I0127 13:36:00.277472  7058 net.cpp:408] pool2 <- conv2\n",
      "I0127 13:36:00.277482  7058 net.cpp:382] pool2 -> pool2\n",
      "I0127 13:36:00.277494  7058 net.cpp:124] Setting up pool2\n",
      "I0127 13:36:00.277501  7058 net.cpp:131] Top shape: 1 192 56 56 (602112)\n",
      "I0127 13:36:00.277513  7058 net.cpp:139] Memory required for data: 52985856\n",
      "I0127 13:36:00.277518  7058 layer_factory.hpp:77] Creating layer conv3\n",
      "I0127 13:36:00.277530  7058 net.cpp:86] Creating Layer conv3\n",
      "I0127 13:36:00.277537  7058 net.cpp:408] conv3 <- pool2\n",
      "I0127 13:36:00.277551  7058 net.cpp:382] conv3 -> conv3\n",
      "I0127 13:36:00.277956  7058 net.cpp:124] Setting up conv3\n",
      "I0127 13:36:00.277967  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:00.277985  7058 net.cpp:139] Memory required for data: 54591488\n",
      "I0127 13:36:00.277998  7058 layer_factory.hpp:77] Creating layer relu3\n",
      "I0127 13:36:00.278008  7058 net.cpp:86] Creating Layer relu3\n",
      "I0127 13:36:00.278015  7058 net.cpp:408] relu3 <- conv3\n",
      "I0127 13:36:00.278024  7058 net.cpp:369] relu3 -> conv3 (in-place)\n",
      "I0127 13:36:00.278034  7058 net.cpp:124] Setting up relu3\n",
      "I0127 13:36:00.278040  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:00.278050  7058 net.cpp:139] Memory required for data: 56197120\n",
      "I0127 13:36:00.278057  7058 layer_factory.hpp:77] Creating layer conv4\n",
      "I0127 13:36:00.278076  7058 net.cpp:86] Creating Layer conv4\n",
      "I0127 13:36:00.278084  7058 net.cpp:408] conv4 <- conv3\n",
      "I0127 13:36:00.278095  7058 net.cpp:382] conv4 -> conv4\n",
      "I0127 13:36:00.288923  7058 net.cpp:124] Setting up conv4\n",
      "I0127 13:36:00.288942  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:36:00.288956  7058 net.cpp:139] Memory required for data: 59408384\n",
      "I0127 13:36:00.288969  7058 layer_factory.hpp:77] Creating layer relu4\n",
      "I0127 13:36:00.288980  7058 net.cpp:86] Creating Layer relu4\n",
      "I0127 13:36:00.288988  7058 net.cpp:408] relu4 <- conv4\n",
      "I0127 13:36:00.289001  7058 net.cpp:369] relu4 -> conv4 (in-place)\n",
      "I0127 13:36:00.289019  7058 net.cpp:124] Setting up relu4\n",
      "I0127 13:36:00.289027  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:36:00.289037  7058 net.cpp:139] Memory required for data: 62619648\n",
      "I0127 13:36:00.289044  7058 layer_factory.hpp:77] Creating layer conv5\n",
      "I0127 13:36:00.289057  7058 net.cpp:86] Creating Layer conv5\n",
      "I0127 13:36:00.289065  7058 net.cpp:408] conv5 <- conv4\n",
      "I0127 13:36:00.289075  7058 net.cpp:382] conv5 -> conv5\n",
      "I0127 13:36:00.291872  7058 net.cpp:124] Setting up conv5\n",
      "I0127 13:36:00.291889  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:36:00.291903  7058 net.cpp:139] Memory required for data: 65830912\n",
      "I0127 13:36:00.291924  7058 layer_factory.hpp:77] Creating layer relu5\n",
      "I0127 13:36:00.291939  7058 net.cpp:86] Creating Layer relu5\n",
      "I0127 13:36:00.291945  7058 net.cpp:408] relu5 <- conv5\n",
      "I0127 13:36:00.291955  7058 net.cpp:369] relu5 -> conv5 (in-place)\n",
      "I0127 13:36:00.291967  7058 net.cpp:124] Setting up relu5\n",
      "I0127 13:36:00.291973  7058 net.cpp:131] Top shape: 1 256 56 56 (802816)\n",
      "I0127 13:36:00.291985  7058 net.cpp:139] Memory required for data: 69042176\n",
      "I0127 13:36:00.291991  7058 layer_factory.hpp:77] Creating layer conv6\n",
      "I0127 13:36:00.292007  7058 net.cpp:86] Creating Layer conv6\n",
      "I0127 13:36:00.292018  7058 net.cpp:408] conv6 <- conv5\n",
      "I0127 13:36:00.292032  7058 net.cpp:382] conv6 -> conv6\n",
      "I0127 13:36:00.319185  7058 net.cpp:124] Setting up conv6\n",
      "I0127 13:36:00.319206  7058 net.cpp:131] Top shape: 1 512 56 56 (1605632)\n",
      "I0127 13:36:00.319219  7058 net.cpp:139] Memory required for data: 75464704\n",
      "I0127 13:36:00.319232  7058 layer_factory.hpp:77] Creating layer relu6\n",
      "I0127 13:36:00.319245  7058 net.cpp:86] Creating Layer relu6\n",
      "I0127 13:36:00.319252  7058 net.cpp:408] relu6 <- conv6\n",
      "I0127 13:36:00.319263  7058 net.cpp:369] relu6 -> conv6 (in-place)\n",
      "I0127 13:36:00.319275  7058 net.cpp:124] Setting up relu6\n",
      "I0127 13:36:00.319283  7058 net.cpp:131] Top shape: 1 512 56 56 (1605632)\n",
      "I0127 13:36:00.319291  7058 net.cpp:139] Memory required for data: 81887232\n",
      "I0127 13:36:00.319298  7058 layer_factory.hpp:77] Creating layer pool6\n",
      "I0127 13:36:00.319306  7058 net.cpp:86] Creating Layer pool6\n",
      "I0127 13:36:00.319312  7058 net.cpp:408] pool6 <- conv6\n",
      "I0127 13:36:00.319321  7058 net.cpp:382] pool6 -> pool6\n",
      "I0127 13:36:00.319336  7058 net.cpp:124] Setting up pool6\n",
      "I0127 13:36:00.319344  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.319353  7058 net.cpp:139] Memory required for data: 83492864\n",
      "I0127 13:36:00.319360  7058 layer_factory.hpp:77] Creating layer conv7\n",
      "I0127 13:36:00.319379  7058 net.cpp:86] Creating Layer conv7\n",
      "I0127 13:36:00.319386  7058 net.cpp:408] conv7 <- pool6\n",
      "I0127 13:36:00.319396  7058 net.cpp:382] conv7 -> conv7\n",
      "I0127 13:36:00.322607  7058 net.cpp:124] Setting up conv7\n",
      "I0127 13:36:00.322625  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.322638  7058 net.cpp:139] Memory required for data: 84295680\n",
      "I0127 13:36:00.322650  7058 layer_factory.hpp:77] Creating layer relu7\n",
      "I0127 13:36:00.322664  7058 net.cpp:86] Creating Layer relu7\n",
      "I0127 13:36:00.322672  7058 net.cpp:408] relu7 <- conv7\n",
      "I0127 13:36:00.322682  7058 net.cpp:369] relu7 -> conv7 (in-place)\n",
      "I0127 13:36:00.322695  7058 net.cpp:124] Setting up relu7\n",
      "I0127 13:36:00.322701  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.322710  7058 net.cpp:139] Memory required for data: 85098496\n",
      "I0127 13:36:00.322717  7058 layer_factory.hpp:77] Creating layer conv8\n",
      "I0127 13:36:00.322736  7058 net.cpp:86] Creating Layer conv8\n",
      "I0127 13:36:00.322743  7058 net.cpp:408] conv8 <- conv7\n",
      "I0127 13:36:00.322753  7058 net.cpp:382] conv8 -> conv8\n",
      "I0127 13:36:00.356405  7058 net.cpp:124] Setting up conv8\n",
      "I0127 13:36:00.356432  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.356447  7058 net.cpp:139] Memory required for data: 86704128\n",
      "I0127 13:36:00.356462  7058 layer_factory.hpp:77] Creating layer relu8\n",
      "I0127 13:36:00.356475  7058 net.cpp:86] Creating Layer relu8\n",
      "I0127 13:36:00.356484  7058 net.cpp:408] relu8 <- conv8\n",
      "I0127 13:36:00.356498  7058 net.cpp:369] relu8 -> conv8 (in-place)\n",
      "I0127 13:36:00.356511  7058 net.cpp:124] Setting up relu8\n",
      "I0127 13:36:00.356518  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.356530  7058 net.cpp:139] Memory required for data: 88309760\n",
      "I0127 13:36:00.356539  7058 layer_factory.hpp:77] Creating layer conv9\n",
      "I0127 13:36:00.356557  7058 net.cpp:86] Creating Layer conv9\n",
      "I0127 13:36:00.356566  7058 net.cpp:408] conv9 <- conv8\n",
      "I0127 13:36:00.356580  7058 net.cpp:382] conv9 -> conv9\n",
      "I0127 13:36:00.358981  7058 net.cpp:124] Setting up conv9\n",
      "I0127 13:36:00.359005  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.359019  7058 net.cpp:139] Memory required for data: 89112576\n",
      "I0127 13:36:00.359032  7058 layer_factory.hpp:77] Creating layer relu9\n",
      "I0127 13:36:00.359045  7058 net.cpp:86] Creating Layer relu9\n",
      "I0127 13:36:00.359051  7058 net.cpp:408] relu9 <- conv9\n",
      "I0127 13:36:00.359061  7058 net.cpp:369] relu9 -> conv9 (in-place)\n",
      "I0127 13:36:00.359071  7058 net.cpp:124] Setting up relu9\n",
      "I0127 13:36:00.359076  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.359088  7058 net.cpp:139] Memory required for data: 89915392\n",
      "I0127 13:36:00.359099  7058 layer_factory.hpp:77] Creating layer conv10\n",
      "I0127 13:36:00.359165  7058 net.cpp:86] Creating Layer conv10\n",
      "I0127 13:36:00.359179  7058 net.cpp:408] conv10 <- conv9\n",
      "I0127 13:36:00.359192  7058 net.cpp:382] conv10 -> conv10\n",
      "I0127 13:36:00.381974  7058 net.cpp:124] Setting up conv10\n",
      "I0127 13:36:00.382031  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.382105  7058 net.cpp:139] Memory required for data: 91521024\n",
      "I0127 13:36:00.382115  7058 layer_factory.hpp:77] Creating layer relu10\n",
      "I0127 13:36:00.382128  7058 net.cpp:86] Creating Layer relu10\n",
      "I0127 13:36:00.382134  7058 net.cpp:408] relu10 <- conv10\n",
      "I0127 13:36:00.382143  7058 net.cpp:369] relu10 -> conv10 (in-place)\n",
      "I0127 13:36:00.382158  7058 net.cpp:124] Setting up relu10\n",
      "I0127 13:36:00.382169  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.382177  7058 net.cpp:139] Memory required for data: 93126656\n",
      "I0127 13:36:00.382182  7058 layer_factory.hpp:77] Creating layer conv11\n",
      "I0127 13:36:00.382256  7058 net.cpp:86] Creating Layer conv11\n",
      "I0127 13:36:00.382267  7058 net.cpp:408] conv11 <- conv10\n",
      "I0127 13:36:00.382280  7058 net.cpp:382] conv11 -> conv11\n",
      "I0127 13:36:00.388057  7058 net.cpp:124] Setting up conv11\n",
      "I0127 13:36:00.388079  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.388092  7058 net.cpp:139] Memory required for data: 93929472\n",
      "I0127 13:36:00.388103  7058 layer_factory.hpp:77] Creating layer relu11\n",
      "I0127 13:36:00.388116  7058 net.cpp:86] Creating Layer relu11\n",
      "I0127 13:36:00.388123  7058 net.cpp:408] relu11 <- conv11\n",
      "I0127 13:36:00.388134  7058 net.cpp:369] relu11 -> conv11 (in-place)\n",
      "I0127 13:36:00.388144  7058 net.cpp:124] Setting up relu11\n",
      "I0127 13:36:00.388150  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.388159  7058 net.cpp:139] Memory required for data: 94732288\n",
      "I0127 13:36:00.388166  7058 layer_factory.hpp:77] Creating layer conv12\n",
      "I0127 13:36:00.388180  7058 net.cpp:86] Creating Layer conv12\n",
      "I0127 13:36:00.388187  7058 net.cpp:408] conv12 <- conv11\n",
      "I0127 13:36:00.388197  7058 net.cpp:382] conv12 -> conv12\n",
      "I0127 13:36:00.418920  7058 net.cpp:124] Setting up conv12\n",
      "I0127 13:36:00.418946  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.418967  7058 net.cpp:139] Memory required for data: 96337920\n",
      "I0127 13:36:00.418987  7058 layer_factory.hpp:77] Creating layer relu12\n",
      "I0127 13:36:00.419006  7058 net.cpp:86] Creating Layer relu12\n",
      "I0127 13:36:00.419015  7058 net.cpp:408] relu12 <- conv12\n",
      "I0127 13:36:00.419028  7058 net.cpp:369] relu12 -> conv12 (in-place)\n",
      "I0127 13:36:00.419045  7058 net.cpp:124] Setting up relu12\n",
      "I0127 13:36:00.419054  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.419065  7058 net.cpp:139] Memory required for data: 97943552\n",
      "I0127 13:36:00.419075  7058 layer_factory.hpp:77] Creating layer conv13\n",
      "I0127 13:36:00.419095  7058 net.cpp:86] Creating Layer conv13\n",
      "I0127 13:36:00.419107  7058 net.cpp:408] conv13 <- conv12\n",
      "I0127 13:36:00.419121  7058 net.cpp:382] conv13 -> conv13\n",
      "I0127 13:36:00.421367  7058 net.cpp:124] Setting up conv13\n",
      "I0127 13:36:00.421387  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.421402  7058 net.cpp:139] Memory required for data: 98746368\n",
      "I0127 13:36:00.421416  7058 layer_factory.hpp:77] Creating layer relu13\n",
      "I0127 13:36:00.421434  7058 net.cpp:86] Creating Layer relu13\n",
      "I0127 13:36:00.421444  7058 net.cpp:408] relu13 <- conv13\n",
      "I0127 13:36:00.421456  7058 net.cpp:369] relu13 -> conv13 (in-place)\n",
      "I0127 13:36:00.421474  7058 net.cpp:124] Setting up relu13\n",
      "I0127 13:36:00.421483  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:00.421492  7058 net.cpp:139] Memory required for data: 99549184\n",
      "I0127 13:36:00.421505  7058 layer_factory.hpp:77] Creating layer conv14\n",
      "I0127 13:36:00.421523  7058 net.cpp:86] Creating Layer conv14\n",
      "I0127 13:36:00.421532  7058 net.cpp:408] conv14 <- conv13\n",
      "I0127 13:36:00.421541  7058 net.cpp:382] conv14 -> conv14\n",
      "I0127 13:36:00.447324  7058 net.cpp:124] Setting up conv14\n",
      "I0127 13:36:00.447345  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.447360  7058 net.cpp:139] Memory required for data: 101154816\n",
      "I0127 13:36:00.447372  7058 layer_factory.hpp:77] Creating layer relu14\n",
      "I0127 13:36:00.447386  7058 net.cpp:86] Creating Layer relu14\n",
      "I0127 13:36:00.447392  7058 net.cpp:408] relu14 <- conv14\n",
      "I0127 13:36:00.447403  7058 net.cpp:369] relu14 -> conv14 (in-place)\n",
      "I0127 13:36:00.447415  7058 net.cpp:124] Setting up relu14\n",
      "I0127 13:36:00.447422  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.447432  7058 net.cpp:139] Memory required for data: 102760448\n",
      "I0127 13:36:00.447439  7058 layer_factory.hpp:77] Creating layer conv15\n",
      "I0127 13:36:00.447463  7058 net.cpp:86] Creating Layer conv15\n",
      "I0127 13:36:00.447471  7058 net.cpp:408] conv15 <- conv14\n",
      "I0127 13:36:00.447482  7058 net.cpp:382] conv15 -> conv15\n",
      "I0127 13:36:00.454058  7058 net.cpp:124] Setting up conv15\n",
      "I0127 13:36:00.454089  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.454106  7058 net.cpp:139] Memory required for data: 104366080\n",
      "I0127 13:36:00.454123  7058 layer_factory.hpp:77] Creating layer relu15\n",
      "I0127 13:36:00.454142  7058 net.cpp:86] Creating Layer relu15\n",
      "I0127 13:36:00.454154  7058 net.cpp:408] relu15 <- conv15\n",
      "I0127 13:36:00.454165  7058 net.cpp:369] relu15 -> conv15 (in-place)\n",
      "I0127 13:36:00.454182  7058 net.cpp:124] Setting up relu15\n",
      "I0127 13:36:00.454190  7058 net.cpp:131] Top shape: 1 512 28 28 (401408)\n",
      "I0127 13:36:00.454202  7058 net.cpp:139] Memory required for data: 105971712\n",
      "I0127 13:36:00.454210  7058 layer_factory.hpp:77] Creating layer conv16\n",
      "I0127 13:36:00.454229  7058 net.cpp:86] Creating Layer conv16\n",
      "I0127 13:36:00.454237  7058 net.cpp:408] conv16 <- conv15\n",
      "I0127 13:36:00.454250  7058 net.cpp:382] conv16 -> conv16\n",
      "I0127 13:36:00.535737  7058 net.cpp:124] Setting up conv16\n",
      "I0127 13:36:00.535758  7058 net.cpp:131] Top shape: 1 1024 28 28 (802816)\n",
      "I0127 13:36:00.535768  7058 net.cpp:139] Memory required for data: 109182976\n",
      "I0127 13:36:00.535777  7058 layer_factory.hpp:77] Creating layer relu16\n",
      "I0127 13:36:00.535810  7058 net.cpp:86] Creating Layer relu16\n",
      "I0127 13:36:00.535828  7058 net.cpp:408] relu16 <- conv16\n",
      "I0127 13:36:00.535838  7058 net.cpp:369] relu16 -> conv16 (in-place)\n",
      "I0127 13:36:00.535851  7058 net.cpp:124] Setting up relu16\n",
      "I0127 13:36:00.535857  7058 net.cpp:131] Top shape: 1 1024 28 28 (802816)\n",
      "I0127 13:36:00.535868  7058 net.cpp:139] Memory required for data: 112394240\n",
      "I0127 13:36:00.535876  7058 layer_factory.hpp:77] Creating layer pool16\n",
      "I0127 13:36:00.535884  7058 net.cpp:86] Creating Layer pool16\n",
      "I0127 13:36:00.535895  7058 net.cpp:408] pool16 <- conv16\n",
      "I0127 13:36:00.535910  7058 net.cpp:382] pool16 -> pool16\n",
      "I0127 13:36:00.535925  7058 net.cpp:124] Setting up pool16\n",
      "I0127 13:36:00.535933  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.535945  7058 net.cpp:139] Memory required for data: 113197056\n",
      "I0127 13:36:00.535952  7058 layer_factory.hpp:77] Creating layer conv17\n",
      "I0127 13:36:00.535965  7058 net.cpp:86] Creating Layer conv17\n",
      "I0127 13:36:00.535972  7058 net.cpp:408] conv17 <- pool16\n",
      "I0127 13:36:00.535981  7058 net.cpp:382] conv17 -> conv17\n",
      "I0127 13:36:00.544701  7058 net.cpp:124] Setting up conv17\n",
      "I0127 13:36:00.544726  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:00.544737  7058 net.cpp:139] Memory required for data: 113598464\n",
      "I0127 13:36:00.544754  7058 layer_factory.hpp:77] Creating layer relu17\n",
      "I0127 13:36:00.544775  7058 net.cpp:86] Creating Layer relu17\n",
      "I0127 13:36:00.544785  7058 net.cpp:408] relu17 <- conv17\n",
      "I0127 13:36:00.544791  7058 net.cpp:369] relu17 -> conv17 (in-place)\n",
      "I0127 13:36:00.544801  7058 net.cpp:124] Setting up relu17\n",
      "I0127 13:36:00.544845  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:00.544862  7058 net.cpp:139] Memory required for data: 113999872\n",
      "I0127 13:36:00.544871  7058 layer_factory.hpp:77] Creating layer conv18\n",
      "I0127 13:36:00.544888  7058 net.cpp:86] Creating Layer conv18\n",
      "I0127 13:36:00.544894  7058 net.cpp:408] conv18 <- conv17\n",
      "I0127 13:36:00.544904  7058 net.cpp:382] conv18 -> conv18\n",
      "I0127 13:36:00.613724  7058 net.cpp:124] Setting up conv18\n",
      "I0127 13:36:00.613749  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.613765  7058 net.cpp:139] Memory required for data: 114802688\n",
      "I0127 13:36:00.613775  7058 layer_factory.hpp:77] Creating layer relu18\n",
      "I0127 13:36:00.613787  7058 net.cpp:86] Creating Layer relu18\n",
      "I0127 13:36:00.613797  7058 net.cpp:408] relu18 <- conv18\n",
      "I0127 13:36:00.613811  7058 net.cpp:369] relu18 -> conv18 (in-place)\n",
      "I0127 13:36:00.613824  7058 net.cpp:124] Setting up relu18\n",
      "I0127 13:36:00.613828  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.613837  7058 net.cpp:139] Memory required for data: 115605504\n",
      "I0127 13:36:00.613842  7058 layer_factory.hpp:77] Creating layer conv19\n",
      "I0127 13:36:00.613855  7058 net.cpp:86] Creating Layer conv19\n",
      "I0127 13:36:00.613864  7058 net.cpp:408] conv19 <- conv18\n",
      "I0127 13:36:00.613896  7058 net.cpp:382] conv19 -> conv19\n",
      "I0127 13:36:00.621023  7058 net.cpp:124] Setting up conv19\n",
      "I0127 13:36:00.621044  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:00.621073  7058 net.cpp:139] Memory required for data: 116006912\n",
      "I0127 13:36:00.621098  7058 layer_factory.hpp:77] Creating layer relu19\n",
      "I0127 13:36:00.621106  7058 net.cpp:86] Creating Layer relu19\n",
      "I0127 13:36:00.621114  7058 net.cpp:408] relu19 <- conv19\n",
      "I0127 13:36:00.621124  7058 net.cpp:369] relu19 -> conv19 (in-place)\n",
      "I0127 13:36:00.621140  7058 net.cpp:124] Setting up relu19\n",
      "I0127 13:36:00.621146  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:00.621155  7058 net.cpp:139] Memory required for data: 116408320\n",
      "I0127 13:36:00.621160  7058 layer_factory.hpp:77] Creating layer conv20\n",
      "I0127 13:36:00.621168  7058 net.cpp:86] Creating Layer conv20\n",
      "I0127 13:36:00.621176  7058 net.cpp:408] conv20 <- conv19\n",
      "I0127 13:36:00.621191  7058 net.cpp:382] conv20 -> conv20\n",
      "I0127 13:36:00.693790  7058 net.cpp:124] Setting up conv20\n",
      "I0127 13:36:00.693812  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.693825  7058 net.cpp:139] Memory required for data: 117211136\n",
      "I0127 13:36:00.693836  7058 layer_factory.hpp:77] Creating layer relu20\n",
      "I0127 13:36:00.693850  7058 net.cpp:86] Creating Layer relu20\n",
      "I0127 13:36:00.693857  7058 net.cpp:408] relu20 <- conv20\n",
      "I0127 13:36:00.693866  7058 net.cpp:369] relu20 -> conv20 (in-place)\n",
      "I0127 13:36:00.693877  7058 net.cpp:124] Setting up relu20\n",
      "I0127 13:36:00.693883  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.693892  7058 net.cpp:139] Memory required for data: 118013952\n",
      "I0127 13:36:00.693900  7058 layer_factory.hpp:77] Creating layer conv21\n",
      "I0127 13:36:00.693928  7058 net.cpp:86] Creating Layer conv21\n",
      "I0127 13:36:00.693936  7058 net.cpp:408] conv21 <- conv20\n",
      "I0127 13:36:00.693944  7058 net.cpp:382] conv21 -> conv21\n",
      "I0127 13:36:00.833576  7058 net.cpp:124] Setting up conv21\n",
      "I0127 13:36:00.833606  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.833621  7058 net.cpp:139] Memory required for data: 118816768\n",
      "I0127 13:36:00.833634  7058 layer_factory.hpp:77] Creating layer relu21\n",
      "I0127 13:36:00.833647  7058 net.cpp:86] Creating Layer relu21\n",
      "I0127 13:36:00.833655  7058 net.cpp:408] relu21 <- conv21\n",
      "I0127 13:36:00.833664  7058 net.cpp:369] relu21 -> conv21 (in-place)\n",
      "I0127 13:36:00.833679  7058 net.cpp:124] Setting up relu21\n",
      "I0127 13:36:00.833690  7058 net.cpp:131] Top shape: 1 1024 14 14 (200704)\n",
      "I0127 13:36:00.833701  7058 net.cpp:139] Memory required for data: 119619584\n",
      "I0127 13:36:00.833707  7058 layer_factory.hpp:77] Creating layer conv22\n",
      "I0127 13:36:00.833722  7058 net.cpp:86] Creating Layer conv22\n",
      "I0127 13:36:00.833745  7058 net.cpp:408] conv22 <- conv21\n",
      "I0127 13:36:00.833755  7058 net.cpp:382] conv22 -> conv22\n",
      "I0127 13:36:00.999300  7058 net.cpp:124] Setting up conv22\n",
      "I0127 13:36:00.999326  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:00.999343  7058 net.cpp:139] Memory required for data: 119820288\n",
      "I0127 13:36:00.999356  7058 layer_factory.hpp:77] Creating layer relu22\n",
      "I0127 13:36:00.999387  7058 net.cpp:86] Creating Layer relu22\n",
      "I0127 13:36:00.999395  7058 net.cpp:408] relu22 <- conv22\n",
      "I0127 13:36:00.999436  7058 net.cpp:369] relu22 -> conv22 (in-place)\n",
      "I0127 13:36:00.999466  7058 net.cpp:124] Setting up relu22\n",
      "I0127 13:36:00.999473  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:00.999513  7058 net.cpp:139] Memory required for data: 120020992\n",
      "I0127 13:36:00.999521  7058 layer_factory.hpp:77] Creating layer conv23\n",
      "I0127 13:36:00.999532  7058 net.cpp:86] Creating Layer conv23\n",
      "I0127 13:36:00.999541  7058 net.cpp:408] conv23 <- conv22\n",
      "I0127 13:36:00.999553  7058 net.cpp:382] conv23 -> conv23\n",
      "I0127 13:36:01.159613  7058 net.cpp:124] Setting up conv23\n",
      "I0127 13:36:01.159637  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:01.159657  7058 net.cpp:139] Memory required for data: 120221696\n",
      "I0127 13:36:01.159670  7058 layer_factory.hpp:77] Creating layer relu23\n",
      "I0127 13:36:01.159698  7058 net.cpp:86] Creating Layer relu23\n",
      "I0127 13:36:01.159705  7058 net.cpp:408] relu23 <- conv23\n",
      "I0127 13:36:01.159715  7058 net.cpp:369] relu23 -> conv23 (in-place)\n",
      "I0127 13:36:01.159727  7058 net.cpp:124] Setting up relu23\n",
      "I0127 13:36:01.159735  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:01.159749  7058 net.cpp:139] Memory required for data: 120422400\n",
      "I0127 13:36:01.159759  7058 layer_factory.hpp:77] Creating layer conv24\n",
      "I0127 13:36:01.159773  7058 net.cpp:86] Creating Layer conv24\n",
      "I0127 13:36:01.159780  7058 net.cpp:408] conv24 <- conv23\n",
      "I0127 13:36:01.159790  7058 net.cpp:382] conv24 -> conv24\n",
      "I0127 13:36:01.294281  7058 net.cpp:124] Setting up conv24\n",
      "I0127 13:36:01.294307  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:01.294318  7058 net.cpp:139] Memory required for data: 120623104\n",
      "I0127 13:36:01.294327  7058 layer_factory.hpp:77] Creating layer relu24\n",
      "I0127 13:36:01.294342  7058 net.cpp:86] Creating Layer relu24\n",
      "I0127 13:36:01.294353  7058 net.cpp:408] relu24 <- conv24\n",
      "I0127 13:36:01.294368  7058 net.cpp:369] relu24 -> conv24 (in-place)\n",
      "I0127 13:36:01.294378  7058 net.cpp:124] Setting up relu24\n",
      "I0127 13:36:01.294382  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:01.294390  7058 net.cpp:139] Memory required for data: 120823808\n",
      "I0127 13:36:01.294399  7058 layer_factory.hpp:77] Creating layer fc25\n",
      "I0127 13:36:01.294414  7058 net.cpp:86] Creating Layer fc25\n",
      "I0127 13:36:01.294420  7058 net.cpp:408] fc25 <- conv24\n",
      "I0127 13:36:01.294428  7058 net.cpp:382] fc25 -> fc25\n",
      "I0127 13:36:01.647998  7058 net.cpp:124] Setting up fc25\n",
      "I0127 13:36:01.648026  7058 net.cpp:131] Top shape: 1 512 (512)\n",
      "I0127 13:36:01.648038  7058 net.cpp:139] Memory required for data: 120825856\n",
      "I0127 13:36:01.648048  7058 layer_factory.hpp:77] Creating layer relu25\n",
      "I0127 13:36:01.648058  7058 net.cpp:86] Creating Layer relu25\n",
      "I0127 13:36:01.648066  7058 net.cpp:408] relu25 <- fc25\n",
      "I0127 13:36:01.648082  7058 net.cpp:369] relu25 -> fc25 (in-place)\n",
      "I0127 13:36:01.648095  7058 net.cpp:124] Setting up relu25\n",
      "I0127 13:36:01.648100  7058 net.cpp:131] Top shape: 1 512 (512)\n",
      "I0127 13:36:01.648108  7058 net.cpp:139] Memory required for data: 120827904\n",
      "I0127 13:36:01.648113  7058 layer_factory.hpp:77] Creating layer fc26\n",
      "I0127 13:36:01.648119  7058 net.cpp:86] Creating Layer fc26\n",
      "I0127 13:36:01.648129  7058 net.cpp:408] fc26 <- fc25\n",
      "I0127 13:36:01.648146  7058 net.cpp:382] fc26 -> fc26\n",
      "I0127 13:36:01.673753  7058 net.cpp:124] Setting up fc26\n",
      "I0127 13:36:01.673774  7058 net.cpp:131] Top shape: 1 4096 (4096)\n",
      "I0127 13:36:01.673789  7058 net.cpp:139] Memory required for data: 120844288\n",
      "I0127 13:36:01.673800  7058 layer_factory.hpp:77] Creating layer relu26\n",
      "I0127 13:36:01.673810  7058 net.cpp:86] Creating Layer relu26\n",
      "I0127 13:36:01.673816  7058 net.cpp:408] relu26 <- fc26\n",
      "I0127 13:36:01.673825  7058 net.cpp:369] relu26 -> fc26 (in-place)\n",
      "I0127 13:36:01.673843  7058 net.cpp:124] Setting up relu26\n",
      "I0127 13:36:01.673851  7058 net.cpp:131] Top shape: 1 4096 (4096)\n",
      "I0127 13:36:01.673894  7058 net.cpp:139] Memory required for data: 120860672\n",
      "I0127 13:36:01.673905  7058 layer_factory.hpp:77] Creating layer fc27\n",
      "I0127 13:36:01.673918  7058 net.cpp:86] Creating Layer fc27\n",
      "I0127 13:36:01.673923  7058 net.cpp:408] fc27 <- fc26\n",
      "I0127 13:36:01.673929  7058 net.cpp:382] fc27 -> result\n",
      "I0127 13:36:01.747505  7058 net.cpp:124] Setting up fc27\n",
      "I0127 13:36:01.747530  7058 net.cpp:131] Top shape: 1 1470 (1470)\n",
      "I0127 13:36:01.747539  7058 net.cpp:139] Memory required for data: 120866552\n",
      "I0127 13:36:01.747550  7058 net.cpp:202] fc27 does not need backward computation.\n",
      "I0127 13:36:01.747560  7058 net.cpp:202] relu26 does not need backward computation.\n",
      "I0127 13:36:01.747570  7058 net.cpp:202] fc26 does not need backward computation.\n",
      "I0127 13:36:01.747578  7058 net.cpp:202] relu25 does not need backward computation.\n",
      "I0127 13:36:01.747583  7058 net.cpp:202] fc25 does not need backward computation.\n",
      "I0127 13:36:01.747588  7058 net.cpp:202] relu24 does not need backward computation.\n",
      "I0127 13:36:01.747593  7058 net.cpp:202] conv24 does not need backward computation.\n",
      "I0127 13:36:01.747598  7058 net.cpp:202] relu23 does not need backward computation.\n",
      "I0127 13:36:01.747602  7058 net.cpp:202] conv23 does not need backward computation.\n",
      "I0127 13:36:01.747611  7058 net.cpp:202] relu22 does not need backward computation.\n",
      "I0127 13:36:01.747642  7058 net.cpp:202] conv22 does not need backward computation.\n",
      "I0127 13:36:01.747650  7058 net.cpp:202] relu21 does not need backward computation.\n",
      "I0127 13:36:01.747656  7058 net.cpp:202] conv21 does not need backward computation.\n",
      "I0127 13:36:01.747661  7058 net.cpp:202] relu20 does not need backward computation.\n",
      "I0127 13:36:01.747670  7058 net.cpp:202] conv20 does not need backward computation.\n",
      "I0127 13:36:01.747679  7058 net.cpp:202] relu19 does not need backward computation.\n",
      "I0127 13:36:01.747689  7058 net.cpp:202] conv19 does not need backward computation.\n",
      "I0127 13:36:01.747695  7058 net.cpp:202] relu18 does not need backward computation.\n",
      "I0127 13:36:01.747700  7058 net.cpp:202] conv18 does not need backward computation.\n",
      "I0127 13:36:01.747705  7058 net.cpp:202] relu17 does not need backward computation.\n",
      "I0127 13:36:01.747711  7058 net.cpp:202] conv17 does not need backward computation.\n",
      "I0127 13:36:01.747716  7058 net.cpp:202] pool16 does not need backward computation.\n",
      "I0127 13:36:01.747727  7058 net.cpp:202] relu16 does not need backward computation.\n",
      "I0127 13:36:01.747738  7058 net.cpp:202] conv16 does not need backward computation.\n",
      "I0127 13:36:01.747748  7058 net.cpp:202] relu15 does not need backward computation.\n",
      "I0127 13:36:01.747753  7058 net.cpp:202] conv15 does not need backward computation.\n",
      "I0127 13:36:01.747761  7058 net.cpp:202] relu14 does not need backward computation.\n",
      "I0127 13:36:01.747766  7058 net.cpp:202] conv14 does not need backward computation.\n",
      "I0127 13:36:01.747771  7058 net.cpp:202] relu13 does not need backward computation.\n",
      "I0127 13:36:01.747776  7058 net.cpp:202] conv13 does not need backward computation.\n",
      "I0127 13:36:01.747785  7058 net.cpp:202] relu12 does not need backward computation.\n",
      "I0127 13:36:01.747794  7058 net.cpp:202] conv12 does not need backward computation.\n",
      "I0127 13:36:01.747805  7058 net.cpp:202] relu11 does not need backward computation.\n",
      "I0127 13:36:01.747812  7058 net.cpp:202] conv11 does not need backward computation.\n",
      "I0127 13:36:01.747817  7058 net.cpp:202] relu10 does not need backward computation.\n",
      "I0127 13:36:01.747821  7058 net.cpp:202] conv10 does not need backward computation.\n",
      "I0127 13:36:01.747826  7058 net.cpp:202] relu9 does not need backward computation.\n",
      "I0127 13:36:01.747831  7058 net.cpp:202] conv9 does not need backward computation.\n",
      "I0127 13:36:01.747840  7058 net.cpp:202] relu8 does not need backward computation.\n",
      "I0127 13:36:01.747849  7058 net.cpp:202] conv8 does not need backward computation.\n",
      "I0127 13:36:01.747860  7058 net.cpp:202] relu7 does not need backward computation.\n",
      "I0127 13:36:01.747866  7058 net.cpp:202] conv7 does not need backward computation.\n",
      "I0127 13:36:01.747871  7058 net.cpp:202] pool6 does not need backward computation.\n",
      "I0127 13:36:01.747877  7058 net.cpp:202] relu6 does not need backward computation.\n",
      "I0127 13:36:01.747882  7058 net.cpp:202] conv6 does not need backward computation.\n",
      "I0127 13:36:01.747887  7058 net.cpp:202] relu5 does not need backward computation.\n",
      "I0127 13:36:01.747893  7058 net.cpp:202] conv5 does not need backward computation.\n",
      "I0127 13:36:01.747903  7058 net.cpp:202] relu4 does not need backward computation.\n",
      "I0127 13:36:01.747915  7058 net.cpp:202] conv4 does not need backward computation.\n",
      "I0127 13:36:01.747921  7058 net.cpp:202] relu3 does not need backward computation.\n",
      "I0127 13:36:01.747926  7058 net.cpp:202] conv3 does not need backward computation.\n",
      "I0127 13:36:01.747932  7058 net.cpp:202] pool2 does not need backward computation.\n",
      "I0127 13:36:01.747937  7058 net.cpp:202] relu2 does not need backward computation.\n",
      "I0127 13:36:01.747943  7058 net.cpp:202] conv2 does not need backward computation.\n",
      "I0127 13:36:01.747948  7058 net.cpp:202] pool1 does not need backward computation.\n",
      "I0127 13:36:01.747958  7058 net.cpp:202] relu1 does not need backward computation.\n",
      "I0127 13:36:01.747969  7058 net.cpp:202] conv1 does not need backward computation.\n",
      "I0127 13:36:01.747977  7058 net.cpp:202] input does not need backward computation.\n",
      "I0127 13:36:01.747982  7058 net.cpp:244] This network produces output result\n",
      "I0127 13:36:01.748029  7058 net.cpp:257] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(62001758,)\n",
      "conv1(conv)\n",
      "conv2(conv)\n",
      "conv3(conv)\n",
      "conv4(conv)\n",
      "conv5(conv)\n",
      "conv6(conv)\n",
      "conv7(conv)\n",
      "conv8(conv)\n",
      "conv9(conv)\n",
      "conv10(conv)\n",
      "conv11(conv)\n",
      "conv12(conv)\n",
      "conv13(conv)\n",
      "conv14(conv)\n",
      "conv15(conv)\n",
      "conv16(conv)\n",
      "conv17(conv)\n",
      "conv18(conv)\n",
      "conv19(conv)\n",
      "conv20(conv)\n",
      "conv21(conv)\n",
      "conv22(conv)\n",
      "conv23(conv)\n",
      "conv24(conv)\n",
      "fc25(fc)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1845278 into shape (512,50176)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m yoloweight_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/yolov3.weights\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m caffemodel_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/yolo_small_train_val.caffemodel\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mgencaffemodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myoloweight_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaffemodel_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mgencaffemodel\u001b[0;34m(model_filename, yoloweight_filename, caffemodel_filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m         net\u001b[38;5;241m.\u001b[39mparams[pr][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(netWeights[count:count\u001b[38;5;241m+\u001b[39mweightSize], (dims[\u001b[38;5;241m1\u001b[39m], dims[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m         net\u001b[38;5;241m.\u001b[39mparams[pr][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetWeights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mweightSize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m weightSize\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatchNorm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:301\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/numpy/core/fromnumeric.py:61\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1845278 into shape (512,50176)"
     ]
    }
   ],
   "source": [
    "model_filename = './Data/yolo_small_train_val.prototxt'\n",
    "yoloweight_filename = './Data/yolov3.weights'\n",
    "caffemodel_filename = './Data/yolo_small_train_val.caffemodel'\n",
    "gencaffemodel(model_filename, yoloweight_filename, caffemodel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc1db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model file is ./Data/yolo_tiny_train_val.prototxt\n",
      "weight file is ./Data/yolov3.weights\n",
      "caffemodel file is ./Data/yolo_tiny_train_val.caffemodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0127 13:36:15.589802  7058 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: ./Data/yolo_tiny_train_val.prototxt\n",
      "I0127 13:36:15.592324  7058 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.\n",
      "W0127 13:36:15.592335  7058 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0127 13:36:15.592344  7058 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./Data/yolo_tiny_train_val.prototxt\n",
      "I0127 13:36:15.592357  7058 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.\n",
      "I0127 13:36:15.593261  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1\n",
      "I0127 13:36:15.593297  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2\n",
      "I0127 13:36:15.593314  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3\n",
      "I0127 13:36:15.593328  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4\n",
      "I0127 13:36:15.593343  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn5\n",
      "I0127 13:36:15.593358  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn6\n",
      "I0127 13:36:15.593369  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn7\n",
      "I0127 13:36:15.593382  7058 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn8\n",
      "I0127 13:36:15.593397  7058 net.cpp:53] Initializing net from parameters: \n",
      "name: \"YOLONet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 448\n",
      "      dim: 448\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 16\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn1\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"bn1\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale1\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn1\"\n",
      "  top: \"scale1\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale1\"\n",
      "  top: \"scale1\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn2\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"bn2\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale2\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn2\"\n",
      "  top: \"scale2\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale2\"\n",
      "  top: \"scale2\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn3\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"bn3\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale3\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn3\"\n",
      "  top: \"scale3\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale3\"\n",
      "  top: \"scale3\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool3\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale3\"\n",
      "  top: \"pool3\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 128\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn4\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"bn4\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale4\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn4\"\n",
      "  top: \"scale4\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale4\"\n",
      "  top: \"scale4\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool4\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale4\"\n",
      "  top: \"pool4\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn5\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"bn5\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale5\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn5\"\n",
      "  top: \"scale5\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale5\"\n",
      "  top: \"scale5\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv6\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"conv6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 512\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn6\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv6\"\n",
      "  top: \"bn6\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale6\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn6\"\n",
      "  top: \"scale6\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale6\"\n",
      "  top: \"scale6\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool6\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"scale6\"\n",
      "  top: \"pool6\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv7\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool6\"\n",
      "  top: \"conv7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 1024\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn7\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv7\"\n",
      "  top: \"bn7\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale7\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn7\"\n",
      "  top: \"scale7\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale7\"\n",
      "  top: \"scale7\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv8_y\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"scale7\"\n",
      "  top: \"conv8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    bias_term: false\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"bn8\"\n",
      "  type: \"BatchNorm\"\n",
      "  bottom: \"conv8\"\n",
      "  top: \"bn8\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  batch_norm_param {\n",
      "    use_global_stats: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"scale8\"\n",
      "  type: \"Scale\"\n",
      "  bottom: \"bn8\"\n",
      "  top: \"scale8\"\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 0\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  scale_param {\n",
      "    bias_term: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu8\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"scale8\"\n",
      "  top: \"scale8\"\n",
      "  relu_param {\n",
      "    negative_slope: 0.1\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc9\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"scale8\"\n",
      "  top: \"result\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 1470\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "I0127 13:36:15.595829  7058 layer_factory.hpp:77] Creating layer input\n",
      "I0127 13:36:15.595850  7058 net.cpp:86] Creating Layer input\n",
      "I0127 13:36:15.595860  7058 net.cpp:382] input -> data\n",
      "I0127 13:36:15.596771  7058 net.cpp:124] Setting up input\n",
      "I0127 13:36:15.596791  7058 net.cpp:131] Top shape: 1 3 448 448 (602112)\n",
      "I0127 13:36:15.596804  7058 net.cpp:139] Memory required for data: 2408448\n",
      "I0127 13:36:15.596812  7058 layer_factory.hpp:77] Creating layer conv1\n",
      "I0127 13:36:15.596832  7058 net.cpp:86] Creating Layer conv1\n",
      "I0127 13:36:15.596839  7058 net.cpp:408] conv1 <- data\n",
      "I0127 13:36:15.596851  7058 net.cpp:382] conv1 -> conv1\n",
      "I0127 13:36:15.596907  7058 net.cpp:124] Setting up conv1\n",
      "I0127 13:36:15.596915  7058 net.cpp:131] Top shape: 1 16 448 448 (3211264)\n",
      "I0127 13:36:15.596926  7058 net.cpp:139] Memory required for data: 15253504\n",
      "I0127 13:36:15.596938  7058 layer_factory.hpp:77] Creating layer bn1\n",
      "I0127 13:36:15.596952  7058 net.cpp:86] Creating Layer bn1\n",
      "I0127 13:36:15.596959  7058 net.cpp:408] bn1 <- conv1\n",
      "I0127 13:36:15.596968  7058 net.cpp:382] bn1 -> bn1\n",
      "I0127 13:36:15.598212  7058 net.cpp:124] Setting up bn1\n",
      "I0127 13:36:15.598230  7058 net.cpp:131] Top shape: 1 16 448 448 (3211264)\n",
      "I0127 13:36:15.598243  7058 net.cpp:139] Memory required for data: 28098560\n",
      "I0127 13:36:15.598264  7058 layer_factory.hpp:77] Creating layer scale1\n",
      "I0127 13:36:15.599342  7058 net.cpp:86] Creating Layer scale1\n",
      "I0127 13:36:15.599362  7058 net.cpp:408] scale1 <- bn1\n",
      "I0127 13:36:15.599401  7058 net.cpp:382] scale1 -> scale1\n",
      "I0127 13:36:15.599432  7058 layer_factory.hpp:77] Creating layer scale1\n",
      "I0127 13:36:15.600539  7058 net.cpp:124] Setting up scale1\n",
      "I0127 13:36:15.600556  7058 net.cpp:131] Top shape: 1 16 448 448 (3211264)\n",
      "I0127 13:36:15.600569  7058 net.cpp:139] Memory required for data: 40943616\n",
      "I0127 13:36:15.600585  7058 layer_factory.hpp:77] Creating layer relu1\n",
      "I0127 13:36:15.600598  7058 net.cpp:86] Creating Layer relu1\n",
      "I0127 13:36:15.600606  7058 net.cpp:408] relu1 <- scale1\n",
      "I0127 13:36:15.600616  7058 net.cpp:369] relu1 -> scale1 (in-place)\n",
      "I0127 13:36:15.600627  7058 net.cpp:124] Setting up relu1\n",
      "I0127 13:36:15.600634  7058 net.cpp:131] Top shape: 1 16 448 448 (3211264)\n",
      "I0127 13:36:15.600644  7058 net.cpp:139] Memory required for data: 53788672\n",
      "I0127 13:36:15.600651  7058 layer_factory.hpp:77] Creating layer pool1\n",
      "I0127 13:36:15.600659  7058 net.cpp:86] Creating Layer pool1\n",
      "I0127 13:36:15.600666  7058 net.cpp:408] pool1 <- scale1\n",
      "I0127 13:36:15.600677  7058 net.cpp:382] pool1 -> pool1\n",
      "I0127 13:36:15.600692  7058 net.cpp:124] Setting up pool1\n",
      "I0127 13:36:15.600699  7058 net.cpp:131] Top shape: 1 16 224 224 (802816)\n",
      "I0127 13:36:15.600709  7058 net.cpp:139] Memory required for data: 56999936\n",
      "I0127 13:36:15.600715  7058 layer_factory.hpp:77] Creating layer conv2\n",
      "I0127 13:36:15.600733  7058 net.cpp:86] Creating Layer conv2\n",
      "I0127 13:36:15.600740  7058 net.cpp:408] conv2 <- pool1\n",
      "I0127 13:36:15.600750  7058 net.cpp:382] conv2 -> conv2\n",
      "I0127 13:36:15.600832  7058 net.cpp:124] Setting up conv2\n",
      "I0127 13:36:15.600841  7058 net.cpp:131] Top shape: 1 32 224 224 (1605632)\n",
      "I0127 13:36:15.600852  7058 net.cpp:139] Memory required for data: 63422464\n",
      "I0127 13:36:15.600862  7058 layer_factory.hpp:77] Creating layer bn2\n",
      "I0127 13:36:15.600872  7058 net.cpp:86] Creating Layer bn2\n",
      "I0127 13:36:15.600879  7058 net.cpp:408] bn2 <- conv2\n",
      "I0127 13:36:15.600888  7058 net.cpp:382] bn2 -> bn2\n",
      "I0127 13:36:15.601225  7058 net.cpp:124] Setting up bn2\n",
      "I0127 13:36:15.601236  7058 net.cpp:131] Top shape: 1 32 224 224 (1605632)\n",
      "I0127 13:36:15.601246  7058 net.cpp:139] Memory required for data: 69844992\n",
      "I0127 13:36:15.601262  7058 layer_factory.hpp:77] Creating layer scale2\n",
      "I0127 13:36:15.601274  7058 net.cpp:86] Creating Layer scale2\n",
      "I0127 13:36:15.601281  7058 net.cpp:408] scale2 <- bn2\n",
      "I0127 13:36:15.601292  7058 net.cpp:382] scale2 -> scale2\n",
      "I0127 13:36:15.601311  7058 layer_factory.hpp:77] Creating layer scale2\n",
      "I0127 13:36:15.601737  7058 net.cpp:124] Setting up scale2\n",
      "I0127 13:36:15.601819  7058 net.cpp:131] Top shape: 1 32 224 224 (1605632)\n",
      "I0127 13:36:15.601853  7058 net.cpp:139] Memory required for data: 76267520\n",
      "I0127 13:36:15.601866  7058 layer_factory.hpp:77] Creating layer relu2\n",
      "I0127 13:36:15.601876  7058 net.cpp:86] Creating Layer relu2\n",
      "I0127 13:36:15.601882  7058 net.cpp:408] relu2 <- scale2\n",
      "I0127 13:36:15.601897  7058 net.cpp:369] relu2 -> scale2 (in-place)\n",
      "I0127 13:36:15.601907  7058 net.cpp:124] Setting up relu2\n",
      "I0127 13:36:15.601913  7058 net.cpp:131] Top shape: 1 32 224 224 (1605632)\n",
      "I0127 13:36:15.601922  7058 net.cpp:139] Memory required for data: 82690048\n",
      "I0127 13:36:15.601928  7058 layer_factory.hpp:77] Creating layer pool2\n",
      "I0127 13:36:15.601939  7058 net.cpp:86] Creating Layer pool2\n",
      "I0127 13:36:15.601945  7058 net.cpp:408] pool2 <- scale2\n",
      "I0127 13:36:15.601953  7058 net.cpp:382] pool2 -> pool2\n",
      "I0127 13:36:15.601966  7058 net.cpp:124] Setting up pool2\n",
      "I0127 13:36:15.601974  7058 net.cpp:131] Top shape: 1 32 112 112 (401408)\n",
      "I0127 13:36:15.601984  7058 net.cpp:139] Memory required for data: 84295680\n",
      "I0127 13:36:15.601990  7058 layer_factory.hpp:77] Creating layer conv3\n",
      "I0127 13:36:15.602005  7058 net.cpp:86] Creating Layer conv3\n",
      "I0127 13:36:15.602010  7058 net.cpp:408] conv3 <- pool2\n",
      "I0127 13:36:15.602020  7058 net.cpp:382] conv3 -> conv3\n",
      "I0127 13:36:15.602326  7058 net.cpp:124] Setting up conv3\n",
      "I0127 13:36:15.602339  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:36:15.602350  7058 net.cpp:139] Memory required for data: 87506944\n",
      "I0127 13:36:15.602360  7058 layer_factory.hpp:77] Creating layer bn3\n",
      "I0127 13:36:15.602380  7058 net.cpp:86] Creating Layer bn3\n",
      "I0127 13:36:15.602387  7058 net.cpp:408] bn3 <- conv3\n",
      "I0127 13:36:15.602397  7058 net.cpp:382] bn3 -> bn3\n",
      "I0127 13:36:15.602452  7058 net.cpp:124] Setting up bn3\n",
      "I0127 13:36:15.602460  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:36:15.602470  7058 net.cpp:139] Memory required for data: 90718208\n",
      "I0127 13:36:15.602550  7058 layer_factory.hpp:77] Creating layer scale3\n",
      "I0127 13:36:15.602596  7058 net.cpp:86] Creating Layer scale3\n",
      "I0127 13:36:15.602603  7058 net.cpp:408] scale3 <- bn3\n",
      "I0127 13:36:15.602613  7058 net.cpp:382] scale3 -> scale3\n",
      "I0127 13:36:15.602629  7058 layer_factory.hpp:77] Creating layer scale3\n",
      "I0127 13:36:15.602958  7058 net.cpp:124] Setting up scale3\n",
      "I0127 13:36:15.602968  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:36:15.602980  7058 net.cpp:139] Memory required for data: 93929472\n",
      "I0127 13:36:15.602994  7058 layer_factory.hpp:77] Creating layer relu3\n",
      "I0127 13:36:15.603003  7058 net.cpp:86] Creating Layer relu3\n",
      "I0127 13:36:15.603009  7058 net.cpp:408] relu3 <- scale3\n",
      "I0127 13:36:15.603018  7058 net.cpp:369] relu3 -> scale3 (in-place)\n",
      "I0127 13:36:15.603027  7058 net.cpp:124] Setting up relu3\n",
      "I0127 13:36:15.603034  7058 net.cpp:131] Top shape: 1 64 112 112 (802816)\n",
      "I0127 13:36:15.603044  7058 net.cpp:139] Memory required for data: 97140736\n",
      "I0127 13:36:15.603050  7058 layer_factory.hpp:77] Creating layer pool3\n",
      "I0127 13:36:15.603060  7058 net.cpp:86] Creating Layer pool3\n",
      "I0127 13:36:15.603067  7058 net.cpp:408] pool3 <- scale3\n",
      "I0127 13:36:15.603075  7058 net.cpp:382] pool3 -> pool3\n",
      "I0127 13:36:15.603086  7058 net.cpp:124] Setting up pool3\n",
      "I0127 13:36:15.603093  7058 net.cpp:131] Top shape: 1 64 56 56 (200704)\n",
      "I0127 13:36:15.603103  7058 net.cpp:139] Memory required for data: 97943552\n",
      "I0127 13:36:15.603109  7058 layer_factory.hpp:77] Creating layer conv4\n",
      "I0127 13:36:15.603124  7058 net.cpp:86] Creating Layer conv4\n",
      "I0127 13:36:15.603132  7058 net.cpp:408] conv4 <- pool3\n",
      "I0127 13:36:15.603142  7058 net.cpp:382] conv4 -> conv4\n",
      "I0127 13:36:15.604470  7058 net.cpp:124] Setting up conv4\n",
      "I0127 13:36:15.604485  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:15.604496  7058 net.cpp:139] Memory required for data: 99549184\n",
      "I0127 13:36:15.604506  7058 layer_factory.hpp:77] Creating layer bn4\n",
      "I0127 13:36:15.604524  7058 net.cpp:86] Creating Layer bn4\n",
      "I0127 13:36:15.604532  7058 net.cpp:408] bn4 <- conv4\n",
      "I0127 13:36:15.604542  7058 net.cpp:382] bn4 -> bn4\n",
      "I0127 13:36:15.604578  7058 net.cpp:124] Setting up bn4\n",
      "I0127 13:36:15.604585  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:15.604595  7058 net.cpp:139] Memory required for data: 101154816\n",
      "I0127 13:36:15.604609  7058 layer_factory.hpp:77] Creating layer scale4\n",
      "I0127 13:36:15.604619  7058 net.cpp:86] Creating Layer scale4\n",
      "I0127 13:36:15.604625  7058 net.cpp:408] scale4 <- bn4\n",
      "I0127 13:36:15.604635  7058 net.cpp:382] scale4 -> scale4\n",
      "I0127 13:36:15.604650  7058 layer_factory.hpp:77] Creating layer scale4\n",
      "I0127 13:36:15.604684  7058 net.cpp:124] Setting up scale4\n",
      "I0127 13:36:15.604692  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:15.604704  7058 net.cpp:139] Memory required for data: 102760448\n",
      "I0127 13:36:15.604717  7058 layer_factory.hpp:77] Creating layer relu4\n",
      "I0127 13:36:15.604725  7058 net.cpp:86] Creating Layer relu4\n",
      "I0127 13:36:15.604732  7058 net.cpp:408] relu4 <- scale4\n",
      "I0127 13:36:15.604740  7058 net.cpp:369] relu4 -> scale4 (in-place)\n",
      "I0127 13:36:15.604749  7058 net.cpp:124] Setting up relu4\n",
      "I0127 13:36:15.604755  7058 net.cpp:131] Top shape: 1 128 56 56 (401408)\n",
      "I0127 13:36:15.604764  7058 net.cpp:139] Memory required for data: 104366080\n",
      "I0127 13:36:15.604770  7058 layer_factory.hpp:77] Creating layer pool4\n",
      "I0127 13:36:15.604779  7058 net.cpp:86] Creating Layer pool4\n",
      "I0127 13:36:15.604785  7058 net.cpp:408] pool4 <- scale4\n",
      "I0127 13:36:15.604799  7058 net.cpp:382] pool4 -> pool4\n",
      "I0127 13:36:15.604812  7058 net.cpp:124] Setting up pool4\n",
      "I0127 13:36:15.604820  7058 net.cpp:131] Top shape: 1 128 28 28 (100352)\n",
      "I0127 13:36:15.604828  7058 net.cpp:139] Memory required for data: 104767488\n",
      "I0127 13:36:15.604835  7058 layer_factory.hpp:77] Creating layer conv5\n",
      "I0127 13:36:15.604854  7058 net.cpp:86] Creating Layer conv5\n",
      "I0127 13:36:15.604861  7058 net.cpp:408] conv5 <- pool4\n",
      "I0127 13:36:15.604871  7058 net.cpp:382] conv5 -> conv5\n",
      "I0127 13:36:15.616899  7058 net.cpp:124] Setting up conv5\n",
      "I0127 13:36:15.616915  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:15.616928  7058 net.cpp:139] Memory required for data: 105570304\n",
      "I0127 13:36:15.616940  7058 layer_factory.hpp:77] Creating layer bn5\n",
      "I0127 13:36:15.616987  7058 net.cpp:86] Creating Layer bn5\n",
      "I0127 13:36:15.616997  7058 net.cpp:408] bn5 <- conv5\n",
      "I0127 13:36:15.617076  7058 net.cpp:382] bn5 -> bn5\n",
      "I0127 13:36:15.617134  7058 net.cpp:124] Setting up bn5\n",
      "I0127 13:36:15.617141  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:15.617151  7058 net.cpp:139] Memory required for data: 106373120\n",
      "I0127 13:36:15.617264  7058 layer_factory.hpp:77] Creating layer scale5\n",
      "I0127 13:36:15.617277  7058 net.cpp:86] Creating Layer scale5\n",
      "I0127 13:36:15.617283  7058 net.cpp:408] scale5 <- bn5\n",
      "I0127 13:36:15.617292  7058 net.cpp:382] scale5 -> scale5\n",
      "I0127 13:36:15.617307  7058 layer_factory.hpp:77] Creating layer scale5\n",
      "I0127 13:36:15.617429  7058 net.cpp:124] Setting up scale5\n",
      "I0127 13:36:15.617435  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:15.617444  7058 net.cpp:139] Memory required for data: 107175936\n",
      "I0127 13:36:15.617455  7058 layer_factory.hpp:77] Creating layer relu5\n",
      "I0127 13:36:15.617465  7058 net.cpp:86] Creating Layer relu5\n",
      "I0127 13:36:15.617501  7058 net.cpp:408] relu5 <- scale5\n",
      "I0127 13:36:15.617578  7058 net.cpp:369] relu5 -> scale5 (in-place)\n",
      "I0127 13:36:15.617588  7058 net.cpp:124] Setting up relu5\n",
      "I0127 13:36:15.617594  7058 net.cpp:131] Top shape: 1 256 28 28 (200704)\n",
      "I0127 13:36:15.617602  7058 net.cpp:139] Memory required for data: 107978752\n",
      "I0127 13:36:15.617609  7058 layer_factory.hpp:77] Creating layer pool5\n",
      "I0127 13:36:15.617617  7058 net.cpp:86] Creating Layer pool5\n",
      "I0127 13:36:15.617624  7058 net.cpp:408] pool5 <- scale5\n",
      "I0127 13:36:15.617694  7058 net.cpp:382] pool5 -> pool5\n",
      "I0127 13:36:15.617746  7058 net.cpp:124] Setting up pool5\n",
      "I0127 13:36:15.617753  7058 net.cpp:131] Top shape: 1 256 14 14 (50176)\n",
      "I0127 13:36:15.617763  7058 net.cpp:139] Memory required for data: 108179456\n",
      "I0127 13:36:15.617903  7058 layer_factory.hpp:77] Creating layer conv6\n",
      "I0127 13:36:15.620082  7058 net.cpp:86] Creating Layer conv6\n",
      "I0127 13:36:15.620107  7058 net.cpp:408] conv6 <- pool5\n",
      "I0127 13:36:15.620121  7058 net.cpp:382] conv6 -> conv6\n",
      "I0127 13:36:15.653538  7058 net.cpp:124] Setting up conv6\n",
      "I0127 13:36:15.653554  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:15.653564  7058 net.cpp:139] Memory required for data: 108580864\n",
      "I0127 13:36:15.653573  7058 layer_factory.hpp:77] Creating layer bn6\n",
      "I0127 13:36:15.653591  7058 net.cpp:86] Creating Layer bn6\n",
      "I0127 13:36:15.653604  7058 net.cpp:408] bn6 <- conv6\n",
      "I0127 13:36:15.653612  7058 net.cpp:382] bn6 -> bn6\n",
      "I0127 13:36:15.653637  7058 net.cpp:124] Setting up bn6\n",
      "I0127 13:36:15.653645  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:15.653652  7058 net.cpp:139] Memory required for data: 108982272\n",
      "I0127 13:36:15.653666  7058 layer_factory.hpp:77] Creating layer scale6\n",
      "I0127 13:36:15.653681  7058 net.cpp:86] Creating Layer scale6\n",
      "I0127 13:36:15.653692  7058 net.cpp:408] scale6 <- bn6\n",
      "I0127 13:36:15.653700  7058 net.cpp:382] scale6 -> scale6\n",
      "I0127 13:36:15.653717  7058 layer_factory.hpp:77] Creating layer scale6\n",
      "I0127 13:36:15.653731  7058 net.cpp:124] Setting up scale6\n",
      "I0127 13:36:15.653736  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:15.653743  7058 net.cpp:139] Memory required for data: 109383680\n",
      "I0127 13:36:15.653751  7058 layer_factory.hpp:77] Creating layer relu6\n",
      "I0127 13:36:15.653759  7058 net.cpp:86] Creating Layer relu6\n",
      "I0127 13:36:15.653764  7058 net.cpp:408] relu6 <- scale6\n",
      "I0127 13:36:15.653774  7058 net.cpp:369] relu6 -> scale6 (in-place)\n",
      "I0127 13:36:15.653789  7058 net.cpp:124] Setting up relu6\n",
      "I0127 13:36:15.653795  7058 net.cpp:131] Top shape: 1 512 14 14 (100352)\n",
      "I0127 13:36:15.653802  7058 net.cpp:139] Memory required for data: 109785088\n",
      "I0127 13:36:15.653807  7058 layer_factory.hpp:77] Creating layer pool6\n",
      "I0127 13:36:15.653815  7058 net.cpp:86] Creating Layer pool6\n",
      "I0127 13:36:15.653820  7058 net.cpp:408] pool6 <- scale6\n",
      "I0127 13:36:15.653826  7058 net.cpp:382] pool6 -> pool6\n",
      "I0127 13:36:15.653836  7058 net.cpp:124] Setting up pool6\n",
      "I0127 13:36:15.653839  7058 net.cpp:131] Top shape: 1 512 7 7 (25088)\n",
      "I0127 13:36:15.653847  7058 net.cpp:139] Memory required for data: 109885440\n",
      "I0127 13:36:15.653851  7058 layer_factory.hpp:77] Creating layer conv7\n",
      "I0127 13:36:15.653872  7058 net.cpp:86] Creating Layer conv7\n",
      "I0127 13:36:15.653880  7058 net.cpp:408] conv7 <- pool6\n",
      "I0127 13:36:15.653888  7058 net.cpp:382] conv7 -> conv7\n",
      "I0127 13:36:15.773458  7058 net.cpp:124] Setting up conv7\n",
      "I0127 13:36:15.773484  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:15.773500  7058 net.cpp:139] Memory required for data: 110086144\n",
      "I0127 13:36:15.773512  7058 layer_factory.hpp:77] Creating layer bn7\n",
      "I0127 13:36:15.773533  7058 net.cpp:86] Creating Layer bn7\n",
      "I0127 13:36:15.773542  7058 net.cpp:408] bn7 <- conv7\n",
      "I0127 13:36:15.773555  7058 net.cpp:382] bn7 -> bn7\n",
      "I0127 13:36:15.773595  7058 net.cpp:124] Setting up bn7\n",
      "I0127 13:36:15.773604  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:15.773617  7058 net.cpp:139] Memory required for data: 110286848\n",
      "I0127 13:36:15.773633  7058 layer_factory.hpp:77] Creating layer scale7\n",
      "I0127 13:36:15.773648  7058 net.cpp:86] Creating Layer scale7\n",
      "I0127 13:36:15.773658  7058 net.cpp:408] scale7 <- bn7\n",
      "I0127 13:36:15.773669  7058 net.cpp:382] scale7 -> scale7\n",
      "I0127 13:36:15.773689  7058 layer_factory.hpp:77] Creating layer scale7\n",
      "I0127 13:36:15.773723  7058 net.cpp:124] Setting up scale7\n",
      "I0127 13:36:15.773733  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:15.773746  7058 net.cpp:139] Memory required for data: 110487552\n",
      "I0127 13:36:15.773759  7058 layer_factory.hpp:77] Creating layer relu7\n",
      "I0127 13:36:15.773772  7058 net.cpp:86] Creating Layer relu7\n",
      "I0127 13:36:15.773779  7058 net.cpp:408] relu7 <- scale7\n",
      "I0127 13:36:15.773789  7058 net.cpp:369] relu7 -> scale7 (in-place)\n",
      "I0127 13:36:15.773802  7058 net.cpp:124] Setting up relu7\n",
      "I0127 13:36:15.773814  7058 net.cpp:131] Top shape: 1 1024 7 7 (50176)\n",
      "I0127 13:36:15.773830  7058 net.cpp:139] Memory required for data: 110688256\n",
      "I0127 13:36:15.773840  7058 layer_factory.hpp:77] Creating layer conv8_y\n",
      "I0127 13:36:15.773864  7058 net.cpp:86] Creating Layer conv8_y\n",
      "I0127 13:36:15.773870  7058 net.cpp:408] conv8_y <- scale7\n",
      "I0127 13:36:15.773880  7058 net.cpp:382] conv8_y -> conv8\n",
      "I0127 13:36:15.819620  7058 net.cpp:124] Setting up conv8_y\n",
      "I0127 13:36:15.819645  7058 net.cpp:131] Top shape: 1 256 7 7 (12544)\n",
      "I0127 13:36:15.819660  7058 net.cpp:139] Memory required for data: 110738432\n",
      "I0127 13:36:15.819676  7058 layer_factory.hpp:77] Creating layer bn8\n",
      "I0127 13:36:15.819716  7058 net.cpp:86] Creating Layer bn8\n",
      "I0127 13:36:15.819730  7058 net.cpp:408] bn8 <- conv8\n",
      "I0127 13:36:15.819744  7058 net.cpp:382] bn8 -> bn8\n",
      "I0127 13:36:15.819778  7058 net.cpp:124] Setting up bn8\n",
      "I0127 13:36:15.819787  7058 net.cpp:131] Top shape: 1 256 7 7 (12544)\n",
      "I0127 13:36:15.819800  7058 net.cpp:139] Memory required for data: 110788608\n",
      "I0127 13:36:15.819818  7058 layer_factory.hpp:77] Creating layer scale8\n",
      "I0127 13:36:15.819835  7058 net.cpp:86] Creating Layer scale8\n",
      "I0127 13:36:15.819844  7058 net.cpp:408] scale8 <- bn8\n",
      "I0127 13:36:15.819855  7058 net.cpp:382] scale8 -> scale8\n",
      "I0127 13:36:15.819875  7058 layer_factory.hpp:77] Creating layer scale8\n",
      "I0127 13:36:15.819905  7058 net.cpp:124] Setting up scale8\n",
      "I0127 13:36:15.819916  7058 net.cpp:131] Top shape: 1 256 7 7 (12544)\n",
      "I0127 13:36:15.819929  7058 net.cpp:139] Memory required for data: 110838784\n",
      "I0127 13:36:15.819942  7058 layer_factory.hpp:77] Creating layer relu8\n",
      "I0127 13:36:15.819953  7058 net.cpp:86] Creating Layer relu8\n",
      "I0127 13:36:15.819994  7058 net.cpp:408] relu8 <- scale8\n",
      "I0127 13:36:15.820008  7058 net.cpp:369] relu8 -> scale8 (in-place)\n",
      "I0127 13:36:15.820021  7058 net.cpp:124] Setting up relu8\n",
      "I0127 13:36:15.820030  7058 net.cpp:131] Top shape: 1 256 7 7 (12544)\n",
      "I0127 13:36:15.820044  7058 net.cpp:139] Memory required for data: 110888960\n",
      "I0127 13:36:15.820053  7058 layer_factory.hpp:77] Creating layer fc9\n",
      "I0127 13:36:15.820065  7058 net.cpp:86] Creating Layer fc9\n",
      "I0127 13:36:15.820073  7058 net.cpp:408] fc9 <- scale8\n",
      "I0127 13:36:15.820086  7058 net.cpp:382] fc9 -> result\n",
      "I0127 13:36:16.150454  7058 net.cpp:124] Setting up fc9\n",
      "I0127 13:36:16.150480  7058 net.cpp:131] Top shape: 1 1470 (1470)\n",
      "I0127 13:36:16.150494  7058 net.cpp:139] Memory required for data: 110894840\n",
      "I0127 13:36:16.150511  7058 net.cpp:202] fc9 does not need backward computation.\n",
      "I0127 13:36:16.150519  7058 net.cpp:202] relu8 does not need backward computation.\n",
      "I0127 13:36:16.150527  7058 net.cpp:202] scale8 does not need backward computation.\n",
      "I0127 13:36:16.150537  7058 net.cpp:202] bn8 does not need backward computation.\n",
      "I0127 13:36:16.150544  7058 net.cpp:202] conv8_y does not need backward computation.\n",
      "I0127 13:36:16.150553  7058 net.cpp:202] relu7 does not need backward computation.\n",
      "I0127 13:36:16.150561  7058 net.cpp:202] scale7 does not need backward computation.\n",
      "I0127 13:36:16.150569  7058 net.cpp:202] bn7 does not need backward computation.\n",
      "I0127 13:36:16.150578  7058 net.cpp:202] conv7 does not need backward computation.\n",
      "I0127 13:36:16.150586  7058 net.cpp:202] pool6 does not need backward computation.\n",
      "I0127 13:36:16.150595  7058 net.cpp:202] relu6 does not need backward computation.\n",
      "I0127 13:36:16.150604  7058 net.cpp:202] scale6 does not need backward computation.\n",
      "I0127 13:36:16.150611  7058 net.cpp:202] bn6 does not need backward computation.\n",
      "I0127 13:36:16.150620  7058 net.cpp:202] conv6 does not need backward computation.\n",
      "I0127 13:36:16.150629  7058 net.cpp:202] pool5 does not need backward computation.\n",
      "I0127 13:36:16.150637  7058 net.cpp:202] relu5 does not need backward computation.\n",
      "I0127 13:36:16.150645  7058 net.cpp:202] scale5 does not need backward computation.\n",
      "I0127 13:36:16.150653  7058 net.cpp:202] bn5 does not need backward computation.\n",
      "I0127 13:36:16.150662  7058 net.cpp:202] conv5 does not need backward computation.\n",
      "I0127 13:36:16.150671  7058 net.cpp:202] pool4 does not need backward computation.\n",
      "I0127 13:36:16.150679  7058 net.cpp:202] relu4 does not need backward computation.\n",
      "I0127 13:36:16.150687  7058 net.cpp:202] scale4 does not need backward computation.\n",
      "I0127 13:36:16.150696  7058 net.cpp:202] bn4 does not need backward computation.\n",
      "I0127 13:36:16.150704  7058 net.cpp:202] conv4 does not need backward computation.\n",
      "I0127 13:36:16.150713  7058 net.cpp:202] pool3 does not need backward computation.\n",
      "I0127 13:36:16.150722  7058 net.cpp:202] relu3 does not need backward computation.\n",
      "I0127 13:36:16.150730  7058 net.cpp:202] scale3 does not need backward computation.\n",
      "I0127 13:36:16.150738  7058 net.cpp:202] bn3 does not need backward computation.\n",
      "I0127 13:36:16.150749  7058 net.cpp:202] conv3 does not need backward computation.\n",
      "I0127 13:36:16.150758  7058 net.cpp:202] pool2 does not need backward computation.\n",
      "I0127 13:36:16.150766  7058 net.cpp:202] relu2 does not need backward computation.\n",
      "I0127 13:36:16.150774  7058 net.cpp:202] scale2 does not need backward computation.\n",
      "I0127 13:36:16.150782  7058 net.cpp:202] bn2 does not need backward computation.\n",
      "I0127 13:36:16.150790  7058 net.cpp:202] conv2 does not need backward computation.\n",
      "I0127 13:36:16.150799  7058 net.cpp:202] pool1 does not need backward computation.\n",
      "I0127 13:36:16.150807  7058 net.cpp:202] relu1 does not need backward computation.\n",
      "I0127 13:36:16.150815  7058 net.cpp:202] scale1 does not need backward computation.\n",
      "I0127 13:36:16.150825  7058 net.cpp:202] bn1 does not need backward computation.\n",
      "I0127 13:36:16.150833  7058 net.cpp:202] conv1 does not need backward computation.\n",
      "I0127 13:36:16.150843  7058 net.cpp:202] input does not need backward computation.\n",
      "I0127 13:36:16.150854  7058 net.cpp:244] This network produces output result\n",
      "I0127 13:36:16.150913  7058 net.cpp:257] Network initialization done.\n"
     ]
    }
   ],
   "source": [
    "model_filename = './Data/yolo_tiny_train_val.prototxt'\n",
    "yoloweight_filename = './Data/yolov3.weights'\n",
    "caffemodel_filename = './Data/yolo_tiny_train_val.caffemodel'\n",
    "gencaffemodel(model_filename, yoloweight_filename, caffemodel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366cb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
